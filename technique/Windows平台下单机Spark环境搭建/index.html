<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Windows平台下单机Spark环境搭建"><meta name="keywords" content="Windows,Big-Data,Hadoop,Spark,Python"><meta name="author" content="yxnchen,undefined"><meta name="copyright" content="yxnchen"><title>Windows平台下单机Spark环境搭建 | YXN's Blog</title><link rel="shortcut icon" href="/favicon-32x32.png"><link rel="stylesheet" href="/css/index.css?version=1.5.6"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css?version=1.5.6"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Java"><span class="toc-number">1.</span> <span class="toc-text">安装Java</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Spark"><span class="toc-number">2.</span> <span class="toc-text">安装Spark</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Hadoop"><span class="toc-number">3.</span> <span class="toc-text">安装Hadoop</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#验证Spark安装成功"><span class="toc-number">4.</span> <span class="toc-text">验证Spark安装成功</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用Spark开发第一个程序"><span class="toc-number">5.</span> <span class="toc-text">使用Spark开发第一个程序</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Python"><span class="toc-number">5.1.</span> <span class="toc-text">Python</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装PySpark"><span class="toc-number">5.1.1.</span> <span class="toc-text">安装PySpark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#在PyCharm中使用PySpark"><span class="toc-number">5.1.2.</span> <span class="toc-text">在PyCharm中使用PySpark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#程序提交到Spark运行"><span class="toc-number">5.1.3.</span> <span class="toc-text">程序提交到Spark运行</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scala-amp-Java"><span class="toc-number">5.2.</span> <span class="toc-text">Scala &amp; Java</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Java"><span class="toc-number">5.2.1.</span> <span class="toc-text">Java</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Java-Lambda"><span class="toc-number">5.2.1.1.</span> <span class="toc-text">Java Lambda</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Java-原生模式"><span class="toc-number">5.2.1.2.</span> <span class="toc-text">Java 原生模式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scala"><span class="toc-number">5.2.2.</span> <span class="toc-text">Scala</span></a></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.jpg"></div><div class="author-info__name text-center">yxnchen</div><div class="author-info__description text-center">We choose to go to the moon.</div><div class="follow-button"><a href="https://github.com/yxnchen" target="_blank">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">6</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">14</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Bookmarks</div><a class="author-info-links__name text-center" href="https://molunerfinn.com" target="_blank">Molunerfinn</a><a class="author-info-links__name text-center" href="https://spencerwoo.com" target="_blank">Spencer Woo</a><a class="author-info-links__name text-center" href="https://wyydsb.xin" target="_blank">Gunjianpan</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/BFR1_Moon.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">YXN's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Posts</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">👨‍🚀</a></span></div><div id="post-info"><div id="post-title">Windows平台下单机Spark环境搭建</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-04-09</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/technique/">technique</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">2.2k</span><span class="post-meta__separator">|</span><span>阅读时长: 9 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-flow.png" alt=""></p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><blockquote>
<p>为了在有限的资源上学习大数据处理与分析技术，借鉴Linux以及部分网上的教程，在Windows10平台搭建Spark环境。本文将简单记录搭建流程以及其中遇到的坑。</p>
</blockquote>
<a id="more"></a>
<p>Spark的部署模式主要有四种：</p>
<ul>
<li>Local模式（单机模式）</li>
<li>Standalone模式（使用Spark自带的简单集群管理器）</li>
<li>YARN模式（使用YARN作为集群管理器）</li>
<li>Mesos模式（使用Mesos作为集群管理器）</li>
</ul>
<h1 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h1><ul>
<li>到 <a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Oracle Java</a> 官网下载JDK并安装，安装路径建议直接选择<code>C:\Java</code>，不要安装在<code>Program Files</code>中（路径有空格会导致后面配置Hadoop比较麻烦）<ul>
<li>添加环境变量<code>JAVA_HOME</code>，值为安装路径，如<code>C:\Java\jdk1.8.0_121</code></li>
<li>在环境变量<code>Path</code>中增加值：<code>%JAVA_HOME%\bin</code></li>
<li>打开命令行测试是否安装成功，输入<code>java -version</code>，应该出现如下信息<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/java-version.png" alt="命令行查看Java版本信息"></li>
</ul>
</li>
</ul>
<h1 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h1><ul>
<li><p>到 <a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">Apache Spark</a> 官网下载预编译的压缩文件，解压到某个路径中不含空格的文件夹下，也就成为Spark的安装路径，如<code>D:\spark</code><br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-dl.png" alt="下载Spark"></p>
<ul>
<li>添加环境变量<code>SPARK_HOME</code>，值为安装路径，如<code>D:\spark</code></li>
<li>在环境变量<code>Path</code>中增加值：<code>%SPARK_HOME%\bin</code>和<code>%SPARK_HOME%\sbin</code></li>
<li>如果下载的Spark版本<code>&gt;=2.3</code>，建议进一步添加环境变量<code>SPARK_LOCAL_HOSTNAME</code>，值为<code>localhost</code></li>
<li><p>进入Spark的配置目录<code>conf</code>，复制一个<code>log4j.properties.template</code>文件并命名为<code>log4j.properties</code>，打开<code>log4j.properties</code>文件，进行如下修改</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># log4j.rootCategory=INFO, console</span><br><span class="line">log4j.rootCategory=WARN, console</span><br></pre></td></tr></table></figure>
</li>
<li><p>同样在Spark的配置目录<code>conf</code>，复制一个<code>spark-env.sh.template</code>文件并命名为<code>spark-env.sh</code>，打开并增加以下一行代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SPARK_LOCAL_IP = 127.0.0.1</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h1><ul>
<li><p>到 <a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener">Apache Hadoop</a> 官网下载预编译的压缩包（这里为了更好对应，选择下载2.7版本），解压到某个路径中不含空格的文件夹下，也就称为Hadoop的安装路径，如<code>D:\hadoop</code><br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/hadoop-dl.png" alt="下载Hadoop（binary版本）"></p>
<ul>
<li>添加环境变量<code>HADOOP_HOME</code>，值为安装路径，如<code>D:\hadoop</code></li>
<li>在环境变量<code>Path</code>中增加值：<code>%HADOOP_HOME%\bin</code>和<code>%HADOOP_HOME%\sbin</code></li>
<li><p>进入Hadoop的配置目录<code>etc\hadoop</code>，打开文件<code>hadoop-env.cmd</code>，修改Java的安装路径，如果Java安装在<code>Program Files</code>可以通过设置为<code>PROGRA~1</code>解决空格报错的问题</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> JAVA_HOME=C:\PROGRA~<span class="number">1</span>\Java\jdk1.<span class="number">8</span>.<span class="number">0</span>_121</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载对应版本的 <a href="https://github.com/steveloughran/winutils" target="_blank" rel="noopener">winutils</a>，把下载到的<code>bin</code>文件夹覆盖到Hadoop安装目录的<code>bin</code>文件夹，确保其中含有<code>winutils.exe</code>文件</p>
</li>
<li><p>新建<code>tmp\hive</code>文件夹，如<code>C:\tmp\hive</code>，命令行导航到Hadoop的<code>bin</code>目录，执行以下授权操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">winutils.exe chmod -R 777 C:\tmp\hive</span><br></pre></td></tr></table></figure>
</li>
<li><p>最后在命令行输入<code>hadoop version</code>测试是否安装成功<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/hadoop-version.png" alt="验证Hadoop安装成功"></p>
</li>
</ul>
</li>
</ul>
<h1 id="验证Spark安装成功"><a href="#验证Spark安装成功" class="headerlink" title="验证Spark安装成功"></a>验证Spark安装成功</h1><ul>
<li>打开命令行，运行<code>spark-shell</code>，应该输入如下内容<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-shell.png" alt="验证Spark安装成功"></li>
<li>此时进入<code>localhost:4040</code>可以看到Spark的Web界面<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-WebUI.png" alt=""></li>
</ul>
<h1 id="使用Spark开发第一个程序"><a href="#使用Spark开发第一个程序" class="headerlink" title="使用Spark开发第一个程序"></a>使用Spark开发第一个程序</h1><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><h3 id="安装PySpark"><a href="#安装PySpark" class="headerlink" title="安装PySpark"></a>安装PySpark</h3><ul>
<li>把Spark安装路径下的<code>python\pyspark</code>文件夹复制到系统Python的包文件夹下，例如在Anaconda环境中，复制到<code>D:\Anaconda3\Lib\site-packages</code>目录下</li>
<li>安装Python包<code>py4j</code>，在命令行运行<code>pip install py4j</code></li>
<li>验证PySpark配置成功，在命令行输入<code>pyspark</code>，应该输出如下内容<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/pyspark.png" alt="验证PySpark环境可用"></li>
</ul>
<h3 id="在PyCharm中使用PySpark"><a href="#在PyCharm中使用PySpark" class="headerlink" title="在PyCharm中使用PySpark"></a>在PyCharm中使用PySpark</h3><blockquote>
<p>下面以一个经典的词频统计（Word Count）程序为例，学习PySpark的使用，词频统计是一个很经典的分布式程序，这里用到中文分词库jieba，去除停用词再进行计数</p>
</blockquote>
<ul>
<li>新建Python工程，并新建脚本<code>wordcount.py</code></li>
<li>在网上随便找一篇新闻报道，复制内容到文本文件<code>news.txt</code>，记住其路径</li>
<li>到GitHub上搜索中文停用词资源，如从 <a href="https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt" target="_blank" rel="noopener">https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt</a> 下载得到<code>stopwords-zh.txt</code></li>
<li>打开脚本并输入如下代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 从pyspark.context模块导入SparkContext</span></span><br><span class="line"><span class="keyword">from</span> pyspark.context <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化一个SparkContext，用于连接Spark集群</span></span><br><span class="line"><span class="comment"># 第一个参数“local”表示以本地模式加载集群</span></span><br><span class="line"><span class="comment"># 第二个参数“WordCount”表示appName，不能有空格</span></span><br><span class="line">spark = SparkContext(<span class="string">"local"</span>, <span class="string">"WordCount"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据，创建弹性式分布数据集（RDD）</span></span><br><span class="line">data = spark.textFile(<span class="string">r"path/to/news.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取中文停用词</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">r'path/to/stopwords-zh.txt'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    s = f.readline()</span><br><span class="line">stop = [i.replace(<span class="string">'\n'</span>,<span class="string">''</span>) <span class="keyword">for</span> i <span class="keyword">in</span> s]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分词并统计词频</span></span><br><span class="line">data = data.flatMap(<span class="keyword">lambda</span> line: jieba.cut(line,cut_all=<span class="keyword">False</span>)).\</span><br><span class="line">    filter(<span class="keyword">lambda</span> w: w <span class="keyword">not</span> <span class="keyword">in</span> stop).\</span><br><span class="line">    map(<span class="keyword">lambda</span> w: (w,<span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> w0, w1: w0 + w1).\</span><br><span class="line">    sortBy(<span class="keyword">lambda</span> x: x[<span class="number">1</span>], ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出前100个高频词汇</span></span><br><span class="line">print(data.take(<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li><p>设置程序运行配置，打开<code>Run-&gt;Edit Configuration</code>，按照如下图所示内容新建一个配置，其中环境变量必须加入<code>SPARK_HOME</code>、<code>HADOOP_HOME</code>以及<code>SPARK_LOCAL_HOSTNAME</code><br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-configuration.png" alt="设置PyCharm运行配置"></p>
</li>
<li><p>运行程序，最后输出前100个高频词语<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/wordcount.png" alt="WordCount程序输出"></p>
</li>
</ul>
<h3 id="程序提交到Spark运行"><a href="#程序提交到Spark运行" class="headerlink" title="程序提交到Spark运行"></a>程序提交到Spark运行</h3><p>上述词频统计代码也可以直接提交到Spark运行，方法如下：</p>
<ul>
<li><p>打开命令行，导航到Spark的安装目录，执行提交任务命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd D:/spark</span><br><span class="line">./bin/spark-submit /path/to/wordcount.py</span><br></pre></td></tr></table></figure>
</li>
<li><p>最后输出类似的执行结果<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/wordcount-shell.png" alt="提交Spark任务，并输出运行结果"></p>
</li>
</ul>
<h2 id="Scala-amp-Java"><a href="#Scala-amp-Java" class="headerlink" title="Scala &amp; Java"></a>Scala &amp; Java</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul>
<li>在 IntelliJ IDEA 新建一个Maven工程</li>
<li><p>在项目的Maven配置文件<code>pom.xml</code>中加入Spark-core依赖，根据安装的Spark版本到 <a href="https://mvnrepository.com/artifact/org.apache.spark/spark-core" target="_blank" rel="noopener">Maven Repository</a> 仓库找到对应的Maven依赖文本，如：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>打开工程目录下的主程序文件，通常为<code>./src/main/java/App.java</code>，编写词频统计代码</p>
</li>
<li>下面将以两种形式进行编写，Java Lambda的代码风格接近Python，易于阅读；而Java原生模式则稍显复杂</li>
</ul>
<h4 id="Java-Lambda"><a href="#Java-Lambda" class="headerlink" title="Java Lambda"></a>Java Lambda</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Word count!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 创建Spark实例</span></span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"WordCount"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext jsc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 读取数据，这里是一个关于Spark介绍的文本</span></span><br><span class="line">        String filename = <span class="string">"path/to/spark.txt"</span>;</span><br><span class="line">        JavaRDD&lt;String&gt; data = jsc.textFile(filename);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 切割压平</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataMap = data.flatMap(t -&gt; Arrays.asList(t.split(<span class="string">" "</span>)).iterator());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 组合成元组</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataPair = dataMap.mapToPair(t -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(t,<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 分组聚合</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataAgg = dataPair.reduceByKey((w1,w2) -&gt; w1+w2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 交换key，再排序</span></span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSwap = dataAgg.mapToPair(tp -&gt; tp.swap());</span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSort = dataSwap.sortByKey(<span class="keyword">false</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; result = dataSort.mapToPair(tp -&gt; tp.swap());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保存结果，saveAsTextFile()方法是将RDD写到本地，根据执行task的多少生成多少个文件</span></span><br><span class="line">        <span class="comment">// 输出目录不能预先存在，否则报错</span></span><br><span class="line">        result.saveAsTextFile(<span class="string">"path/to/spark_count"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出第一个</span></span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; resList = result.collect();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; tp: resList)&#123;</span><br><span class="line">            System.out.println(tp._1+<span class="string">"\t"</span>+tp._2);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>最后打开输出结果文件夹的<code>part-00000</code>文件，输出各个单词的统计数：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(Spark,7)</span><br><span class="line">(and,7)</span><br><span class="line">(the,5)</span><br><span class="line">(Apache,5)</span><br><span class="line">(of,4)</span><br><span class="line">(for,3)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Java-原生模式"><a href="#Java-原生模式" class="headerlink" title="Java 原生模式"></a>Java 原生模式</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function2;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.PairFunction;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Word count!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 创建Spark实例</span></span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"WordCount"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext jsc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 读取数据，这里是一个关于Spark介绍的文本</span></span><br><span class="line">        String filename = <span class="string">"path/to/spark.txt"</span>;</span><br><span class="line">        JavaRDD&lt;String&gt; data = jsc.textFile(filename);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 切割压平</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataMap = data.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(s.split(<span class="string">" "</span>)).iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 组合成元组</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataPair = dataMap.mapToPair(<span class="keyword">new</span> PairFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(s,<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 分组聚合</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataAgg = dataPair.reduceByKey(<span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer w1, Integer w2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> w1 + w2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 交换key，再排序</span></span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSwap = dataAgg.mapToPair(<span class="keyword">new</span> PairFunction&lt;Tuple2&lt;String, Integer&gt;, Integer, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;Integer, String&gt; <span class="title">call</span><span class="params">(Tuple2&lt;String, Integer&gt; tp)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> tp.swap();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSort = dataSwap.sortByKey(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; result = dataSort.mapToPair(<span class="keyword">new</span> PairFunction&lt;Tuple2&lt;Integer, String&gt;, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(Tuple2&lt;Integer, String&gt; tp)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> tp.swap();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保存结果，saveAsTextFile()方法是将RDD写到本地，根据执行task的多少生成多少个文件</span></span><br><span class="line">        <span class="comment">// 输出目录不能预先存在，否则报错</span></span><br><span class="line">        result.saveAsTextFile(<span class="string">"path/to/spark_count"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出第一个</span></span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; resList = result.collect();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; tp: resList)&#123;</span><br><span class="line">            System.out.println(tp._1+<span class="string">"\t"</span>+tp._2);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>最后结果与上面情况类似</li>
</ul>
<h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><p>（待更新）</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">yxnchen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yxnchen.github.io/technique/Windows平台下单机Spark环境搭建/">http://yxnchen.github.io/technique/Windows平台下单机Spark环境搭建/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yxnchen.github.io" target="_blank">YXN's Blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Windows/">Windows</a><a class="post-meta__tags" href="/tags/Big-Data/">Big-Data</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/Spark/">Spark</a><a class="post-meta__tags" href="/tags/Python/">Python</a></div><nav id="pagination"><div class="next-post pull-right"><a href="/technique/我的Windows装机必备应用/"><span>我的Windows装机必备应用</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2019 By yxnchen</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.6"></script><script src="/js/fancybox.js?version=1.5.6"></script><script src="/js/sidebar.js?version=1.5.6"></script><script src="/js/copy.js?version=1.5.6"></script><script src="/js/fireworks.js?version=1.5.6"></script><script src="/js/transition.js?version=1.5.6"></script><script src="/js/scroll.js?version=1.5.6"></script><script src="/js/head.js?version=1.5.6"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>