<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Spark笔记-玩转RDD操作</title>
      <link href="/technique/Spark%E7%AC%94%E8%AE%B0-%E7%8E%A9%E8%BD%ACRDD%E6%93%8D%E4%BD%9C/"/>
      <url>/technique/Spark%E7%AC%94%E8%AE%B0-%E7%8E%A9%E8%BD%ACRDD%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<blockquote><p>RDD（Resilient Distributed Dataset）译作<strong>弹性分布式数据集</strong>，是Spark中最常用的数据抽象，是一个只可读、可分区、可并行计算的数据集合。RDD允许将工作集缓存在内存中进行复用，大大地提升了查询速度。</p></blockquote><a id="more"></a><h1 id="RDD简介"><a href="#RDD简介" class="headerlink" title="RDD简介"></a>RDD简介</h1><ul><li>MapReduce 在面对日益复杂的业务逻辑时已经表现出严重的不足：1）维护成本高昂，每一次数据处理都需要编写复杂的Map和Reduce步骤，中间某一步骤出错就要重试以处理异常；2）难以上手，处理性能睇；</li><li>因此人们想出用<strong>有向无环图</strong>（DAG）来抽象表达复杂的数据处理逻辑，各个数据处理步骤表示成图中的节点与边依赖关系，形成数据流的抽象表示，而把复杂的性能优化提交给后台自动处理；</li><li>RDD也即分布式对象集合，是一个<strong>只读</strong>的分区记录集合，每个RDD可以划分成多个<strong>分区</strong>，每个分区就是数据集的一部分，同时不同分区可以存储在集群中不同的节点上，从而利用集群节点优势进行并行计算；</li><li>RDD提供了丰富的操作以支持常见的数据处理，即“转换”（Transformation）和“行动”（Action）两种类型操作<ul><li><strong>转换</strong>操作指定RDD的依赖关系，通过接受RDD并返回RDD；</li><li><strong>行动</strong>操作执行计算并指定输出的形式，通过接受RDD返回输出值或结果（非RDD）；</li></ul></li><li>通过Spark的API可以使用不同的语言调用RDD的操作，常见过程流程如下：<ul><li>从各种数据源创建RDD；</li><li>对RDD指定一系列的转换操作；</li><li>最后调用行动操作，输出结果或写入外部数据源；</li></ul></li><li>RDD操作的<strong>惰性机制</strong>，是指在RDD执行操作时，只有触发行动操作才会做真正的计算，而在行动前的所有转换操作都只是记录下相互的依赖关系，形成数据流的管道化（pipeline），而不会做真正的计算；</li></ul><p><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-rdd-DAG.png" alt="Spark RDD 的执行过程"></p><h1 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h1><h2 id="通过数据集合转化为RDD"><a href="#通过数据集合转化为RDD" class="headerlink" title="通过数据集合转化为RDD"></a>通过数据集合转化为RDD</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sc = SparkContext(<span class="string">"local"</span>, <span class="string">"create_rdd"</span>)</span><br><span class="line">ints = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]</span><br><span class="line">rdd = sc.parallelize(ints)</span><br><span class="line">strings = [<span class="string">'spark'</span>,<span class="string">'hadoop'</span>,<span class="string">'rdd'</span>]</span><br><span class="line">rdd = sc.parallelize(strings)</span><br></pre></td></tr></table></figure><h2 id="从HDFS数据源或本地文件创建"><a href="#从HDFS数据源或本地文件创建" class="headerlink" title="从HDFS数据源或本地文件创建"></a>从HDFS数据源或本地文件创建</h2><p>从一篇CNN新闻报道 <a href="https://us.cnn.com/2019/04/11/tech/uber-lyft-businesses/index.html" target="_blank" rel="noopener">Uber and Lyft may look the same, but their visions are not</a> 中抽取新闻主体并放到文件<code>news_sep.txt</code>中，一段话为一行。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">At first blush, it can be hard to tell Uber and ...</span><br><span class="line">But look under the hood and there&apos;s a clear difference ...</span><br><span class="line">Uber filed paperwork on Thursday for what is expected ...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>通过指定文件路径读取为RDD：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sc = SparkContext(<span class="string">"local"</span>, <span class="string">"create_rdd"</span>)</span><br><span class="line"><span class="comment"># 从本地文件系统地址加载</span></span><br><span class="line">rdd = sc.textFile(<span class="string">"file:///path/to/news_sep.txt"</span>)</span><br><span class="line"><span class="comment"># 从分布式文件系统HDFS地址加载，下面三种方式等价</span></span><br><span class="line">rdd = sc.textFile(<span class="string">"hdfs://localhost:9000/path/to/news_sep.txt"</span>)</span><br><span class="line">rdd = sc.textFile(<span class="string">"/path/to/news_sep.txt"</span>)</span><br><span class="line">rdd = sc.textFile(<span class="string">"news_sep.txt"</span>)</span><br></pre></td></tr></table></figure><h2 id="从其他数据库读取数据创建"><a href="#从其他数据库读取数据创建" class="headerlink" title="从其他数据库读取数据创建"></a>从其他数据库读取数据创建</h2><p>（待更新）</p><h2 id="使用数据流创建"><a href="#使用数据流创建" class="headerlink" title="使用数据流创建"></a>使用数据流创建</h2><p>结合流数据处理技术，如Spark Streaming、Kafka以及flume等，通过接收实时的输入数据流创建RDD。</p><h1 id="一般RDD的转换操作（Transformation）"><a href="#一般RDD的转换操作（Transformation）" class="headerlink" title="一般RDD的转换操作（Transformation）"></a>一般RDD的转换操作（Transformation）</h1><p><a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" target="_blank" rel="noopener">官方API文档</a>详细列出转换操作函数，下面简单介绍RDD常用的转换操作：</p><h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap()"></a>flatMap()</h2><p><code>flatMap(func)</code>：对于每一个输入元素，通过指定函数映射到0或多个元素，输出新的RDD。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将上述新闻文本的每一行每一段话根据空格进行分词</span></span><br><span class="line">rdd = rdd.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure></p><h2 id="map"><a href="#map" class="headerlink" title="map()"></a>map()</h2><p><code>map(func)</code>：对于每一个输入元素，通过执行指定函数映射到唯一输出（1v1关系），产生新的RDD<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对上述分词结果的RDD中每一个单词去除标点符号，并转化为小写</span></span><br><span class="line">rdd = rdd.map(<span class="keyword">lambda</span> w: w.strip(<span class="string">"\""</span>).strip(<span class="string">","</span>).strip(<span class="string">"."</span>).lower())</span><br></pre></td></tr></table></figure></p><h2 id="filter"><a href="#filter" class="headerlink" title="filter()"></a>filter()</h2><p><code>filter(func)</code>：是对RDD元素进行过滤，把经过指定函数后返回值为true的元素组成一个新的RDD。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对上述结果筛选掉一些常见的介词，如</span></span><br><span class="line">rm_words = [<span class="string">"and"</span>,<span class="string">"in"</span>,<span class="string">"at"</span>,<span class="string">"a"</span>,<span class="string">"an"</span>,<span class="string">"is"</span>,<span class="string">"are"</span>,<span class="string">"may"</span>,<span class="string">"that"</span>,<span class="string">"this"</span>,<span class="string">"to"</span>,<span class="string">"as"</span>,<span class="string">"with"</span>,<span class="string">"of"</span>,<span class="string">"can"</span>,<span class="string">"be"</span>]</span><br><span class="line">rdd = rdd.filter(<span class="keyword">lambda</span> w: w <span class="keyword">not</span> <span class="keyword">in</span> rm_words)</span><br></pre></td></tr></table></figure></p><h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct()"></a>distinct()</h2><p><code>distinct([numPartitions])</code>：对数据进行去重，返回一个新的RDD，numPartitions参数用于设置任务并行数。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输出新闻中所有提及过的单词</span></span><br><span class="line">rdd = rdd.distinct(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p><h2 id="sample"><a href="#sample" class="headerlink" title="sample()"></a>sample()</h2><p><code>sample(withReplacement,fraction,seed=None)</code>：对数据进行采样，withReplacement参数表示是否放回抽样；fraction参数表示抽样比例；seed表示随机种子。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 随机抽取新闻提及部分单词</span></span><br><span class="line">rdd1 = rdd.sample(<span class="keyword">False</span>, <span class="number">0.2</span>, <span class="number">2019</span>)</span><br></pre></td></tr></table></figure></p><h2 id="union"><a href="#union" class="headerlink" title="union()"></a>union()</h2><p><code>union(otherRDD)</code>：可以与另一个RDD数据集合并，返回一个新的RDD。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd1 = sc.parallelize([<span class="string">"union"</span>,<span class="string">"other"</span>,<span class="string">"rdd"</span>])</span><br><span class="line">rdd = rdd.union(rdd1)</span><br></pre></td></tr></table></figure></p><h2 id="intersection"><a href="#intersection" class="headerlink" title="intersection()"></a>intersection()</h2><p><code>intersection(otherRDD)</code>：可以与另一个RDD数据集进行求交集计算，返回新的RDD。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd1 = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">rdd2 = sc.parallelize([<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">rdd3 = rdd1.intersection(rdd2)</span><br><span class="line"><span class="comment"># 最后rdd3的结果为 [3,4,5]</span></span><br></pre></td></tr></table></figure></p><h2 id="subtract"><a href="#subtract" class="headerlink" title="subtract()"></a>subtract()</h2><p><code>subtract(otherRDD,[numPartitions])</code>：是对otherRDD进行减法操作，将原始RDD的元素减去新输入RDD的元素，将差值返回新RDD。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd1 = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">rdd2 = sc.parallelize([<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line">rdd3 = rdd1.subtract(rdd2)</span><br><span class="line"><span class="comment"># 最后rdd3的结果为 [1,3,5]</span></span><br></pre></td></tr></table></figure></p><h2 id="cartesian"><a href="#cartesian" class="headerlink" title="cartesian()"></a>cartesian()</h2><p><code>cartesian(otherRDD)</code>：可以对两个RDD数据集U，V求笛卡尔积，返回一个新的RDD数据集，其中每个元素为(u,v)。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd1 = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">rdd2 = sc.parallelize([<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">rdd3 = rdd1.cartesian(rdd2)</span><br><span class="line"><span class="comment"># 最后rdd3的结果为 [(1,3),(1,4),(2,3),(2,4)]</span></span><br></pre></td></tr></table></figure></p><h1 id="键值对RDD的转换操作（Transformation）"><a href="#键值对RDD的转换操作（Transformation）" class="headerlink" title="键值对RDD的转换操作（Transformation）"></a>键值对RDD的转换操作（Transformation）</h1><h2 id="map-1"><a href="#map-1" class="headerlink" title="map()"></a>map()</h2><p><code>map(func)</code>：操作可以将一般RDD转换为键值对RDD，元素变成(K,V)。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对上述新闻分词结果的RDD中每一个单词转化为(w,1)键值对</span></span><br><span class="line">rdd = rdd.map(<span class="keyword">lambda</span> w: (w,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></p><h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey()"></a>reduceByKey()</h2><p><code>reduceByKey(func,[numPartitions])</code>：可以对具有相同键的值进行合并，返回一个新的键值对RDD，numPartitions用于设置任务并行数。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对新闻出现过的单词进行词频统计</span></span><br><span class="line">rdd = rdd.reduceByKey(<span class="keyword">lambda</span> w1,w2: w1+w2)</span><br></pre></td></tr></table></figure></p><h2 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey()"></a>groupByKey()</h2><p><code>groupByKey([numPartitions])</code>：可以对具有相同键的值进行分组，返回一个元素为(K,[Iterable])的键值对RDD，numPartitions用于指定任务并行数，默认为8。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对新闻出现过的单词进行词频统计</span></span><br><span class="line">rdd = rdd.groupByKey()</span><br></pre></td></tr></table></figure></p><h2 id="aggregateByKey"><a href="#aggregateByKey" class="headerlink" title="aggregateByKey()"></a>aggregateByKey()</h2><p><code>aggregateByKey(zeroValue,seqFunc,combFunc,[numPartitions])</code>：可以对具有相同键的值进行聚合，把(K,V)键值对RDD转换为新的(K,U)键值对RDD，其中U由给定的combFunc和中立零值zeroValue聚合而成，U可以有与V不一致的形式；</p><ul><li>zeroValue 可以是0如果聚合的目的是求和，可以是List如果目的是对值进行统合，可以是Set如果目的是聚合唯一值；</li><li>seqFunc: (U,V) =&gt; U 对分区内的元素进行聚合（操作发生在每个分区内部）；</li><li>combFunc: (U,U) =&gt; U 对不同分区的聚合结果做进一步的聚合（操作发生在全部分区的聚合结果间）；</li><li>numPartitions 用于设置任务并行数；</li></ul><blockquote><p>为什么使用两个函数？见<a href="https://backtobazics.com/big-data/spark/apache-spark-aggregatebykey-example/" target="_blank" rel="noopener">Apache Spark aggregateByKey Example</a></p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 同样对新闻出现过的单词进行词频统计</span></span><br><span class="line">rdd = rdd.aggregateByKey(<span class="number">0</span>,<span class="keyword">lambda</span> v1,v2: v1+v2, <span class="keyword">lambda</span> a1,a2: a1+a2)</span><br></pre></td></tr></table></figure><h2 id="combineByKey"><a href="#combineByKey" class="headerlink" title="combineByKey()"></a>combineByKey()</h2><p><code>combineByKey(createCombiner,mergeValue,mergeCombiners,[numPartitions])</code>：可以对具有相同键的值按照自定义函数的逻辑进行聚合，把(K,V)键值对RDD转换为新的(K,U)键值对RDD，U可以有与V不一致的形式；</p><ul><li>createCombiner: V =&gt; C 创建新的聚合器方便后续步骤操作，对原始值进行附加操作并返回，跟flatMap()类似；</li><li>mergeValue: (C,V) =&gt; C 对分区内的元素进行聚合（操作发生在每个分区内部）；</li><li>mergeCombiners: (C,C) =&gt; C 对不同分区的聚合结果做进一步的聚合（操作发生在全部分区的聚合结果间）；</li><li>numPartitions 用于设置任务并行数；</li></ul><blockquote><p>groupByKey(), groupByKey(), aggregateByKey() 等都不同程度上依赖于 combineByKey() 操作</p></blockquote><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对词频统计的结果求频数均值，例如</span></span><br><span class="line">strings = [<span class="string">'spark'</span>,<span class="string">'hadoop'</span>,<span class="string">'rdd'</span>,<span class="string">'rdd'</span>,<span class="string">'spark'</span>,<span class="string">'rdd'</span>]</span><br><span class="line">rdd = sc.parallelize(strings)</span><br><span class="line">rdd = rdd.map(<span class="keyword">lambda</span> w: (w,<span class="number">1</span>))</span><br><span class="line">rdd = rdd.reduceByKey(<span class="keyword">lambda</span> v1,v2: v1 + v2)</span><br><span class="line">rdd = rdd.combineByKey(<span class="keyword">lambda</span> v: (<span class="number">1</span>,v), <span class="keyword">lambda</span> c, v: (c[<span class="number">0</span>]+<span class="number">1</span>,c[<span class="number">1</span>]+v), <span class="keyword">lambda</span> c1, c2: (c1[<span class="number">0</span>]+c1[<span class="number">0</span>],c2[<span class="number">1</span>]+c2[<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 最后的结果为 [('spark', (1, 2)), ('hadoop', (1, 1)), ('rdd', (1, 3))]</span></span><br></pre></td></tr></table></figure><h2 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey()"></a>sortByKey()</h2><p><code>sortByKey(ascending,[numPartitions])</code>：可以对键值对RDD按照键进行排序操作，其中K需要实现Ordered方法。</p><ul><li>ascending 决定RDD中的元素按升序还是降序排序，默认是True升序；</li><li>numPartitions 用于设置任务并行数；</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对词频统计结果按降序排序（先把K-V值互换）</span></span><br><span class="line">rdd = rdd.map(<span class="keyword">lambda</span> v: (v[<span class="number">1</span>],v[<span class="number">0</span>]))</span><br><span class="line">rdd = rdd.sortByKey(<span class="keyword">False</span>)</span><br><span class="line">rdd = rdd.map(<span class="keyword">lambda</span> v: (v[<span class="number">1</span>],v[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><h2 id="keys-与values"><a href="#keys-与values" class="headerlink" title="keys()与values()"></a>keys()与values()</h2><p><code>keys(),values()</code>：分别把键值对RDD的key和value返回形成一个新的RDD。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获得上一步排序结果的key或value</span></span><br><span class="line">rdd = rdd.keys()</span><br><span class="line">rdd = rdd.values()</span><br></pre></td></tr></table></figure></p><h2 id="mapValues"><a href="#mapValues" class="headerlink" title="mapValues()"></a>mapValues()</h2><p><code>mapValues(func)</code>：可以对键值对RDD每个元素的value加载到预定义函数进行操作，而不改变key。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 例如对词频统计结果值都减去1</span></span><br><span class="line">rdd = rdd.mapValues(<span class="keyword">lambda</span> v: v - <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><h2 id="join"><a href="#join" class="headerlink" title="join()"></a>join()</h2><p><code>join(otherRDD,[numPartitions])</code>：与关系数据库查询一样，表示内连接，给定两个键值对RDD如(K,V1)和(K,V2)，对于两个数据集都存在的key才对其输出，得到一个新的RDD，元素为(K,(V1,V2))。除此以外，还包括其他情形：</p><ul><li>fullOuterJoin(otherRDD,[numPartitions]) 全连接</li><li>leftOuterJoin(otherRDD,[numPartitions]) 左外连接</li><li>rightOuterJoin(otherRDD,[numPartitions]) 右外连接</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd1 = sc.parallelize([(<span class="string">'spark'</span>,<span class="number">1</span>),(<span class="string">'hadoop'</span>,<span class="number">1</span>)])</span><br><span class="line">rdd2 = sc.parallelize([(<span class="string">'spark'</span>,<span class="number">1</span>)])</span><br><span class="line">rdd1 = rdd1.join(rdd2)</span><br><span class="line"><span class="comment"># 最后结果为 [('spark', (1,1))]</span></span><br></pre></td></tr></table></figure><h1 id="RDD的行动操作（Action）"><a href="#RDD的行动操作（Action）" class="headerlink" title="RDD的行动操作（Action）"></a>RDD的行动操作（Action）</h1><p><a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#actions" target="_blank" rel="noopener">官方API文档</a>详细列出行动操作函数，下面简单介绍常用的行动操作：</p><h2 id="count"><a href="#count" class="headerlink" title="count()"></a>count()</h2><p><code>count()</code>：返回RDD数据集中元素的个数。</p><h2 id="collect"><a href="#collect" class="headerlink" title="collect()"></a>collect()</h2><p><code>collect()</code>：以数组的形式返回RDD数据集的所有元素。</p><h2 id="first"><a href="#first" class="headerlink" title="first()"></a>first()</h2><p><code>first()</code>：返回RDD数据集的第一个元素。</p><h2 id="top"><a href="#top" class="headerlink" title="top()"></a>top()</h2><p><code>top(num,key=None)</code>：以数组的形式返回RDD数据集的前num个元素，默认按<strong>降序</strong>，或者通过key函数指定。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">5</span>,<span class="number">24</span>,<span class="number">3</span>,<span class="number">12</span>,<span class="number">46</span>])</span><br><span class="line">print(rdd.takeOrdered(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 输出 [46,24,12]</span></span><br><span class="line">rdd = sc.parallelize([<span class="number">5</span>,<span class="number">24</span>,<span class="number">3</span>,<span class="number">12</span>,<span class="number">46</span>])</span><br><span class="line">print(rdd.takeOrdered(<span class="number">3</span>, key=str))</span><br><span class="line"><span class="comment"># 输出 [5,46,3]</span></span><br></pre></td></tr></table></figure></p><h2 id="take"><a href="#take" class="headerlink" title="take()"></a>take()</h2><p><code>take(num)</code>：以数组的形式返回RDD数据集的前num个元素。</p><h2 id="takeOrdered"><a href="#takeOrdered" class="headerlink" title="takeOrdered()"></a>takeOrdered()</h2><p><code>takeOrdered(num,key=None)</code>：以数组的形式返回RDD数据集的前num个元素，默认按<strong>升序</strong>排序，或者通过key函数指定。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">print(rdd.takeOrdered(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 输出 [1,2,3]</span></span><br><span class="line">rdd = sc.parallelize([<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">print(rdd.takeOrdered(<span class="number">3</span>, key=<span class="keyword">lambda</span> x: -x))</span><br><span class="line"><span class="comment"># 输出 [5,4,3]</span></span><br></pre></td></tr></table></figure></p><h2 id="takeSample"><a href="#takeSample" class="headerlink" title="takeSample()"></a>takeSample()</h2><p><code>takeSample(withReplacement,num,seed=None)</code>：对RDD数据集进行采样，并以数组的形式返回，withReplacement参数表示是否放回抽样；num参数表示抽样个数；seed表示随机种子。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">print(rdd.takeSample(<span class="keyword">False</span>,<span class="number">3</span>,seed=<span class="number">2019</span>))</span><br></pre></td></tr></table></figure></p><h2 id="lookup"><a href="#lookup" class="headerlink" title="lookup()"></a>lookup()</h2><p><code>lookup(key)</code>：以数组的形式返回键值对RDD中键为key的所有值，如果RDD数据集经过特定转换操作按照key进行了分区，那么此行动操作效率会很高。</p><h2 id="foreach"><a href="#foreach" class="headerlink" title="foreach()"></a>foreach()</h2><p><code>foreach(func)</code>：将RDD数据集中的每个元素加载到指定函数进行操作，无返回值。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对转换结果逐个输出</span></span><br><span class="line">rdd.foreach(<span class="keyword">print</span>)</span><br></pre></td></tr></table></figure></p><h2 id="reduce"><a href="#reduce" class="headerlink" title="reduce()"></a>reduce()</h2><p><code>reduce(func)</code>：通过指定函数（如求和、统计）对RDD数据集元素进行聚合。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对所有元素进行求和</span></span><br><span class="line">sum = rdd.reduce(<span class="keyword">lambda</span> v1,v2: v1 + v2)</span><br></pre></td></tr></table></figure></p><h2 id="aggregate"><a href="#aggregate" class="headerlink" title="aggregate()"></a>aggregate()</h2><p><code>aggregate(zeroValue,seqOp,combOp)</code>：对RDD数据集的元素进行聚合，不要求返回值类型与RDD类型一致；</p><ul><li>zeroValue: U 给定初始值，形式与最终返回值U一致；</li><li>seqOp: (U,V) =&gt; U 对分区内的元素进行聚合（操作发生在每个分区内部）；</li><li>combOp: (U,U) =&gt; U 对不同分区的聚合结果做进一步的聚合（操作发生在全部分区的聚合结果间）；</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 求一个数组元素的均值</span></span><br><span class="line">rdd = sc.parallelize([<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">res = rdd.aggregate((<span class="number">0</span>,<span class="number">0</span>), <span class="keyword">lambda</span> u,v: (u[<span class="number">0</span>]+v,u[<span class="number">1</span>]+<span class="number">1</span>), <span class="keyword">lambda</span> u1,u2: (u1[<span class="number">0</span>]+u2[<span class="number">0</span>],u1[<span class="number">1</span>]+u2[<span class="number">1</span>]))</span><br><span class="line">print(res[<span class="number">0</span>]/res[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h2 id="countByKey"><a href="#countByKey" class="headerlink" title="countByKey()"></a>countByKey()</h2><p><code>countByKey()</code>：以字典的形式返回键值对RDD数据集中每个键的元素的统计数，即(K,count)<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">"rdd"</span>,<span class="number">1</span>),(<span class="string">"rdd"</span>,<span class="number">2</span>),(<span class="string">"spark"</span>,<span class="number">2</span>)])</span><br><span class="line">res = rdd.countByKey()</span><br><span class="line"><span class="comment"># 输出结果 &#123;'rdd': 2, 'spark': 1&#125;</span></span><br></pre></td></tr></table></figure></p><h2 id="countByValue"><a href="#countByValue" class="headerlink" title="countByValue()"></a>countByValue()</h2><p><code>countByValue()</code>：以字典的形式返回RDD数据集中每个元素的统计数，即(V,count)<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">res = rdd.countByValue()</span><br><span class="line"><span class="comment"># 输出结果 &#123;2: 2, 3: 1, 1: 2&#125;</span></span><br></pre></td></tr></table></figure></p><h2 id="saveAsTextFile"><a href="#saveAsTextFile" class="headerlink" title="saveAsTextFile()"></a>saveAsTextFile()</h2><p><code>saveAsTextFile(path, compressionCodecClass=None)</code>：把RDD数据集保存为文本文件，并可以指定是否压缩。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f = NamedTemporaryFile(delete=<span class="keyword">True</span>)</span><br><span class="line">f.close()</span><br><span class="line">codec = <span class="string">"org.apache.hadoop.io.compress.GzipCodec"</span></span><br><span class="line">sc.parallelize([<span class="string">'spark'</span>, <span class="string">'rdd'</span>]).saveAsTextFile(f.name, codec)</span><br></pre></td></tr></table></figure></p><h1 id="RDD的持久化"><a href="#RDD的持久化" class="headerlink" title="RDD的持久化"></a>RDD的持久化</h1><ul><li>由于RDD采用惰性机制，每次遇到行动操作都会根据DAG的依赖关系从头开始执行计算，如果遇到迭代计算，需要重复调用中间数据，会造成极大的计算开销；</li><li>可以通过持久化操作来解决以上的问题，用<code>persist()</code>方法对需要重复使用的RDD标记为持久化，当遇到第一次行动操作后，会把计算结果持久化，保存在计算节点的内存备用；</li></ul><h2 id="persist"><a href="#persist" class="headerlink" title="persist()"></a>persist()</h2><p><code>persist(storageLevel)</code>：storageLevel参数表示持久化级别，通过使用不同的级别可以把数据缓存到不同的位置，详见 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence" target="_blank" rel="noopener">RDD Persistence</a>；其中使用<code>cache()</code>函数会调用默认的持久化方法，即<code>persist(MEMORY_ONLY)</code>将RDD作为反序列化的对象存储在JVM中；而<code>unpersist()</code>方法则可以把持久化的RDD从缓存中删除。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="string">'spark'</span>,<span class="string">'rdd'</span>,<span class="string">'hadoop'</span>])</span><br><span class="line">rdd.cache()</span><br><span class="line">print(rdd.take(<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 第一次行动操作，触发完整计算，同时把rdd放入缓存</span></span><br><span class="line"><span class="comment"># 输出 ['spark']</span></span><br><span class="line">print(rdd.collect())</span><br><span class="line"><span class="comment"># 第二次行动操作，此时直接重复利用上述的缓存rdd</span></span><br><span class="line"><span class="comment"># 输出 ['spark','rdd','hadoop']</span></span><br><span class="line">rdd.unpersist()</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> technique </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Big-Data </tag>
            
            <tag> Spark </tag>
            
            <tag> Python </tag>
            
            <tag> RDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows平台下单机Spark环境搭建</title>
      <link href="/technique/Windows%E5%B9%B3%E5%8F%B0%E4%B8%8B%E5%8D%95%E6%9C%BASpark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
      <url>/technique/Windows%E5%B9%B3%E5%8F%B0%E4%B8%8B%E5%8D%95%E6%9C%BASpark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-flow.png" alt=""></p><blockquote><p>为了在有限的资源上学习大数据处理与分析技术，借鉴Linux以及部分网上的教程，在Windows10平台搭建Spark环境。本文将简单记录搭建流程以及其中遇到的坑。</p></blockquote><a id="more"></a><p>Spark的部署模式主要有四种：</p><ul><li>Local模式（单机模式）</li><li>Standalone模式（使用Spark自带的简单集群管理器）</li><li>YARN模式（使用YARN作为集群管理器）</li><li>Mesos模式（使用Mesos作为集群管理器）</li></ul><h1 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h1><ul><li>到 <a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Oracle Java</a> 官网下载JDK并安装，安装路径建议直接选择<code>C:\Java</code>，不要安装在<code>Program Files</code>中（路径有空格会导致后面配置Hadoop比较麻烦）<ul><li>添加环境变量<code>JAVA_HOME</code>，值为安装路径，如<code>C:\Java\jdk1.8.0_121</code></li><li>在环境变量<code>Path</code>中增加值：<code>%JAVA_HOME%\bin</code></li><li>打开命令行测试是否安装成功，输入<code>java -version</code>，应该出现如下信息<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/java-version.png" alt="命令行查看Java版本信息"></li></ul></li></ul><h1 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h1><ul><li><p>到 <a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">Apache Spark</a> 官网下载预编译的压缩文件，解压到某个路径中不含空格的文件夹下，也就成为Spark的安装路径，如<code>D:\spark</code><br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-dl.png" alt="下载Spark"></p><ul><li>添加环境变量<code>SPARK_HOME</code>，值为安装路径，如<code>D:\spark</code></li><li>在环境变量<code>Path</code>中增加值：<code>%SPARK_HOME%\bin</code>和<code>%SPARK_HOME%\sbin</code></li><li>如果下载的Spark版本<code>&gt;=2.3</code>，建议进一步添加环境变量<code>SPARK_LOCAL_HOSTNAME</code>，值为<code>localhost</code></li><li><p>进入Spark的配置目录<code>conf</code>，复制一个<code>log4j.properties.template</code>文件并命名为<code>log4j.properties</code>，打开<code>log4j.properties</code>文件，进行如下修改</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># log4j.rootCategory=INFO, console</span><br><span class="line">log4j.rootCategory=WARN, console</span><br></pre></td></tr></table></figure></li><li><p>同样在Spark的配置目录<code>conf</code>，复制一个<code>spark-env.sh.template</code>文件并命名为<code>spark-env.sh</code>，打开并增加以下一行代码</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SPARK_LOCAL_IP = 127.0.0.1</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h1><ul><li><p>到 <a href="https://hadoop.apache.org/releases.html" target="_blank" rel="noopener">Apache Hadoop</a> 官网下载预编译的压缩包（这里为了更好对应，选择下载2.7版本），解压到某个路径中不含空格的文件夹下，也就称为Hadoop的安装路径，如<code>D:\hadoop</code><br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/hadoop-dl.png" alt="下载Hadoop（binary版本）"></p><ul><li>添加环境变量<code>HADOOP_HOME</code>，值为安装路径，如<code>D:\hadoop</code></li><li>在环境变量<code>Path</code>中增加值：<code>%HADOOP_HOME%\bin</code>和<code>%HADOOP_HOME%\sbin</code></li><li><p>进入Hadoop的配置目录<code>etc\hadoop</code>，打开文件<code>hadoop-env.cmd</code>，修改Java的安装路径，如果Java安装在<code>Program Files</code>可以通过设置为<code>PROGRA~1</code>解决空格报错的问题</p><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> JAVA_HOME=C:\PROGRA~<span class="number">1</span>\Java\jdk1.<span class="number">8</span>.<span class="number">0</span>_121</span><br></pre></td></tr></table></figure></li><li><p>下载对应版本的 <a href="https://github.com/steveloughran/winutils" target="_blank" rel="noopener">winutils</a>，把下载到的<code>bin</code>文件夹覆盖到Hadoop安装目录的<code>bin</code>文件夹，确保其中含有<code>winutils.exe</code>文件</p></li><li><p>新建<code>tmp\hive</code>文件夹，如<code>C:\tmp\hive</code>，命令行导航到Hadoop的<code>bin</code>目录，执行以下授权操作</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">winutils.exe chmod -R 777 C:\tmp\hive</span><br></pre></td></tr></table></figure></li><li><p>最后在命令行输入<code>hadoop version</code>测试是否安装成功<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/hadoop-version.png" alt="验证Hadoop安装成功"></p></li></ul></li></ul><h1 id="验证Spark安装成功"><a href="#验证Spark安装成功" class="headerlink" title="验证Spark安装成功"></a>验证Spark安装成功</h1><ul><li>打开命令行，运行<code>spark-shell</code>，应该输入如下内容<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-shell.png" alt="验证Spark安装成功"></li><li>此时进入<code>localhost:4040</code>可以看到Spark的Web界面<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-WebUI.png" alt=""></li></ul><h1 id="使用Spark开发第一个程序"><a href="#使用Spark开发第一个程序" class="headerlink" title="使用Spark开发第一个程序"></a>使用Spark开发第一个程序</h1><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><h3 id="安装PySpark"><a href="#安装PySpark" class="headerlink" title="安装PySpark"></a>安装PySpark</h3><ul><li>把Spark安装路径下的<code>python\pyspark</code>文件夹复制到系统Python的包文件夹下，例如在Anaconda环境中，复制到<code>D:\Anaconda3\Lib\site-packages</code>目录下</li><li>安装Python包<code>py4j</code>，在命令行运行<code>pip install py4j</code></li><li>验证PySpark配置成功，在命令行输入<code>pyspark</code>，应该输出如下内容<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/pyspark.png" alt="验证PySpark环境可用"></li></ul><h3 id="在PyCharm中使用PySpark"><a href="#在PyCharm中使用PySpark" class="headerlink" title="在PyCharm中使用PySpark"></a>在PyCharm中使用PySpark</h3><blockquote><p>下面以一个经典的词频统计（Word Count）程序为例，学习PySpark的使用，词频统计是一个很经典的分布式程序，这里用到中文分词库jieba，去除停用词再进行计数</p></blockquote><ul><li>新建Python工程，并新建脚本<code>wordcount.py</code></li><li>在网上随便找一篇新闻报道，复制内容到文本文件<code>news.txt</code>，记住其路径</li><li>到GitHub上搜索中文停用词资源，如从 <a href="https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt" target="_blank" rel="noopener">https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt</a> 下载得到<code>stopwords-zh.txt</code></li><li>打开脚本并输入如下代码</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 从pyspark.context模块导入SparkContext</span></span><br><span class="line"><span class="keyword">from</span> pyspark.context <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化一个SparkContext，用于连接Spark集群</span></span><br><span class="line"><span class="comment"># 第一个参数“local”表示以本地模式加载集群</span></span><br><span class="line"><span class="comment"># 第二个参数“WordCount”表示appName，不能有空格</span></span><br><span class="line">spark = SparkContext(<span class="string">"local"</span>, <span class="string">"WordCount"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据，创建弹性式分布数据集（RDD）</span></span><br><span class="line">data = spark.textFile(<span class="string">r"path/to/news.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取中文停用词</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">r'path/to/stopwords-zh.txt'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    s = f.readline()</span><br><span class="line">stop = [i.replace(<span class="string">'\n'</span>,<span class="string">''</span>) <span class="keyword">for</span> i <span class="keyword">in</span> s]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分词并统计词频</span></span><br><span class="line">data = data.flatMap(<span class="keyword">lambda</span> line: jieba.cut(line,cut_all=<span class="keyword">False</span>)).\</span><br><span class="line">    filter(<span class="keyword">lambda</span> w: w <span class="keyword">not</span> <span class="keyword">in</span> stop).\</span><br><span class="line">    map(<span class="keyword">lambda</span> w: (w,<span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> w0, w1: w0 + w1).\</span><br><span class="line">    sortBy(<span class="keyword">lambda</span> x: x[<span class="number">1</span>], ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出前100个高频词汇</span></span><br><span class="line">print(data.take(<span class="number">100</span>))</span><br></pre></td></tr></table></figure><ul><li><p>设置程序运行配置，打开<code>Run-&gt;Edit Configuration</code>，按照如下图所示内容新建一个配置，其中环境变量必须加入<code>SPARK_HOME</code>、<code>HADOOP_HOME</code>以及<code>SPARK_LOCAL_HOSTNAME</code><br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/spark-configuration.png" alt="设置PyCharm运行配置"></p></li><li><p>运行程序，最后输出前100个高频词语<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/wordcount.png" alt="WordCount程序输出"></p></li></ul><h3 id="程序提交到Spark运行"><a href="#程序提交到Spark运行" class="headerlink" title="程序提交到Spark运行"></a>程序提交到Spark运行</h3><p>上述词频统计代码也可以直接提交到Spark运行，方法如下：</p><ul><li><p>打开命令行，导航到Spark的安装目录，执行提交任务命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd D:/spark</span><br><span class="line">./bin/spark-submit /path/to/wordcount.py</span><br></pre></td></tr></table></figure></li><li><p>最后输出类似的执行结果<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/wordcount-shell.png" alt="提交Spark任务，并输出运行结果"></p></li></ul><h2 id="Scala-amp-Java"><a href="#Scala-amp-Java" class="headerlink" title="Scala &amp; Java"></a>Scala &amp; Java</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul><li>在 IntelliJ IDEA 新建一个Maven工程</li><li><p>在项目的Maven配置文件<code>pom.xml</code>中加入Spark-core依赖，根据安装的Spark版本到 <a href="https://mvnrepository.com/artifact/org.apache.spark/spark-core" target="_blank" rel="noopener">Maven Repository</a> 仓库找到对应的Maven依赖文本，如：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>打开工程目录下的主程序文件，通常为<code>./src/main/java/App.java</code>，编写词频统计代码</p></li><li>下面将以两种形式进行编写，Java Lambda的代码风格接近Python，易于阅读；而Java原生模式则稍显复杂</li></ul><h4 id="Java-Lambda"><a href="#Java-Lambda" class="headerlink" title="Java Lambda"></a>Java Lambda</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Word count!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 创建Spark实例</span></span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"WordCount"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext jsc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 读取数据，这里是一个关于Spark介绍的文本</span></span><br><span class="line">        String filename = <span class="string">"path/to/spark.txt"</span>;</span><br><span class="line">        JavaRDD&lt;String&gt; data = jsc.textFile(filename);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 切割压平</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataMap = data.flatMap(t -&gt; Arrays.asList(t.split(<span class="string">" "</span>)).iterator());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 组合成元组</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataPair = dataMap.mapToPair(t -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(t,<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 分组聚合</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataAgg = dataPair.reduceByKey((w1,w2) -&gt; w1+w2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 交换key，再排序</span></span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSwap = dataAgg.mapToPair(tp -&gt; tp.swap());</span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSort = dataSwap.sortByKey(<span class="keyword">false</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; result = dataSort.mapToPair(tp -&gt; tp.swap());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保存结果，saveAsTextFile()方法是将RDD写到本地，根据执行task的多少生成多少个文件</span></span><br><span class="line">        <span class="comment">// 输出目录不能预先存在，否则报错</span></span><br><span class="line">        result.saveAsTextFile(<span class="string">"path/to/spark_count"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出第一个</span></span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; resList = result.collect();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; tp: resList)&#123;</span><br><span class="line">            System.out.println(tp._1+<span class="string">"\t"</span>+tp._2);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>最后打开输出结果文件夹的<code>part-00000</code>文件，输出各个单词的统计数：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(Spark,7)</span><br><span class="line">(and,7)</span><br><span class="line">(the,5)</span><br><span class="line">(Apache,5)</span><br><span class="line">(of,4)</span><br><span class="line">(for,3)</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li></ul><h4 id="Java-原生模式"><a href="#Java-原生模式" class="headerlink" title="Java 原生模式"></a>Java 原生模式</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function2;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.PairFunction;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Word count!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 创建Spark实例</span></span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"WordCount"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line">        JavaSparkContext jsc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 读取数据，这里是一个关于Spark介绍的文本</span></span><br><span class="line">        String filename = <span class="string">"path/to/spark.txt"</span>;</span><br><span class="line">        JavaRDD&lt;String&gt; data = jsc.textFile(filename);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 切割压平</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataMap = data.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterator&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(s.split(<span class="string">" "</span>)).iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 组合成元组</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataPair = dataMap.mapToPair(<span class="keyword">new</span> PairFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(s,<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 分组聚合</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; dataAgg = dataPair.reduceByKey(<span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer w1, Integer w2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> w1 + w2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 交换key，再排序</span></span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSwap = dataAgg.mapToPair(<span class="keyword">new</span> PairFunction&lt;Tuple2&lt;String, Integer&gt;, Integer, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;Integer, String&gt; <span class="title">call</span><span class="params">(Tuple2&lt;String, Integer&gt; tp)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> tp.swap();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;Integer, String&gt; dataSort = dataSwap.sortByKey(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; result = dataSort.mapToPair(<span class="keyword">new</span> PairFunction&lt;Tuple2&lt;Integer, String&gt;, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(Tuple2&lt;Integer, String&gt; tp)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> tp.swap();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保存结果，saveAsTextFile()方法是将RDD写到本地，根据执行task的多少生成多少个文件</span></span><br><span class="line">        <span class="comment">// 输出目录不能预先存在，否则报错</span></span><br><span class="line">        result.saveAsTextFile(<span class="string">"path/to/spark_count"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出第一个</span></span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; resList = result.collect();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; tp: resList)&#123;</span><br><span class="line">            System.out.println(tp._1+<span class="string">"\t"</span>+tp._2);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>最后结果与上面情况类似</li></ul><h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><p>（待更新）</p>]]></content>
      
      
      <categories>
          
          <category> technique </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Windows </tag>
            
            <tag> Big-Data </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Spark </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的Windows装机必备应用</title>
      <link href="/technique/%E6%88%91%E7%9A%84Windows%E8%A3%85%E6%9C%BA%E5%BF%85%E5%A4%87%E5%BA%94%E7%94%A8/"/>
      <url>/technique/%E6%88%91%E7%9A%84Windows%E8%A3%85%E6%9C%BA%E5%BF%85%E5%A4%87%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/windows10-laptop.jpg" alt=""></p><blockquote><p>本文记录本人使用Windows的必备软件工具，以及在使用中的设置习惯。</p></blockquote><a id="more"></a><h1 id="UWP应用"><a href="#UWP应用" class="headerlink" title="UWP应用"></a>UWP应用</h1><ul><li><code>网易云音乐</code></li><li><code>OneNote</code></li><li><code>Drawboard PDF</code></li><li><code>Microsoft To-Do</code></li><li><code>Termius</code></li></ul><h1 id="网络及通讯"><a href="#网络及通讯" class="headerlink" title="网络及通讯"></a>网络及通讯</h1><ul><li><p><code>Chrome</code>: 利用 <a href="https://www.google.com/chrome/index.html?platform=win64&amp;standalone=1" target="_blank" rel="noopener">https://www.google.com/chrome/index.html?platform=win64&amp;standalone=1</a> 下载最新64位离线安装包</p><ul><li>SwitchyOmega</li><li>JSONView</li><li>Tampermonkey</li><li>OneTab</li><li>Clip to OneNote</li><li>uBlock Origin</li><li>Enhanced GitHub</li><li>Reggy</li><li>Color by Fardos</li><li>View Image</li><li>Better History</li><li>Octotree</li></ul></li><li><p><code>迅雷U享版</code>: <a href="http://u.xunlei.com/" target="_blank" rel="noopener">http://u.xunlei.com/</a></p></li><li><code>坚果云</code>: <a href="https://www.jianguoyun.com/" target="_blank" rel="noopener">https://www.jianguoyun.com/</a></li><li><code>Xshell6/Xftp6</code>: <a href="https://www.netsarang.com/en/free-for-home-school/" target="_blank" rel="noopener">https://www.netsarang.com/en/free-for-home-school/</a></li></ul><h1 id="编辑器"><a href="#编辑器" class="headerlink" title="编辑器"></a>编辑器</h1><ul><li><p><code>Sublime Text 3</code>: <a href="https://www.sublimetext.com/" target="_blank" rel="noopener">https://www.sublimetext.com/</a></p><ul><li>Package Control: <a href="https://packagecontrol.io/" target="_blank" rel="noopener">https://packagecontrol.io/</a></li><li>channel_v3_daily: 解决 Sublime Text 3 拓展包源无法访问问题 <a href="https://github.com/HBLong/channel_v3_daily" target="_blank" rel="noopener">https://github.com/HBLong/channel_v3_daily</a></li><li>Dracula Color Scheme</li><li>Boxy Theme: 第三方备份地址 <a href="https://github.com/balthild/boxy-theme-backup" target="_blank" rel="noopener">https://github.com/balthild/boxy-theme-backup</a></li><li>A File Icon</li><li>LaTeXTools与LaTeX-cwl </li></ul></li><li><p><code>Visual Studio Code</code>: <a href="https://code.visualstudio.com/" target="_blank" rel="noopener">https://code.visualstudio.com/</a></p><ul><li>sftp</li><li>Dracula Official</li><li>Excel Viewer</li><li>LaTeX Workshop</li><li>Markdown Preview Enhanced</li><li>Prettify JSON</li><li>REST Client</li><li>VSCode Map Preview</li></ul></li><li><p><code>Typora</code>: <a href="https://typora.io/" target="_blank" rel="noopener">https://typora.io/</a></p><ul><li>Ursine Theme</li></ul></li></ul><h1 id="查看器"><a href="#查看器" class="headerlink" title="查看器"></a>查看器</h1><ul><li><code>SumatraPDF</code>: <a href="https://www.sumatrapdfreader.org/free-pdf-reader.html" target="_blank" rel="noopener">https://www.sumatrapdfreader.org/free-pdf-reader.html</a></li><li><code>Potplayer</code>: <a href="http://potplayer.daum.net/?lang=zh_CN" target="_blank" rel="noopener">http://potplayer.daum.net/?lang=zh_CN</a></li><li><code>Office 365</code>: <a href="https://www.office.com/" target="_blank" rel="noopener">https://www.office.com/</a></li></ul><h1 id="实用工具"><a href="#实用工具" class="headerlink" title="实用工具"></a>实用工具</h1><ul><li><code>Bandizip</code>: <a href="https://en.bandisoft.com/bandizip/" target="_blank" rel="noopener">https://en.bandisoft.com/bandizip/</a></li><li><code>Everything</code>: <a href="https://www.voidtools.com/" target="_blank" rel="noopener">https://www.voidtools.com/</a></li><li><code>Wox</code>: <a href="http://www.wox.one/" target="_blank" rel="noopener">http://www.wox.one/</a></li><li><code>UltraISO</code>: <a href="https://cn.ultraiso.net/" target="_blank" rel="noopener">https://cn.ultraiso.net/</a></li><li><code>Rufus</code>: <a href="https://rufus.ie/" target="_blank" rel="noopener">https://rufus.ie/</a></li></ul><h1 id="语言环境"><a href="#语言环境" class="headerlink" title="语言环境"></a>语言环境</h1><ul><li><code>Python</code>: <a href="https://repo.continuum.io/archive/" target="_blank" rel="noopener">https://repo.continuum.io/archive/</a><ul><li>版本对应关系: <a href="https://blog.csdn.net/yuejisuo1948/article/details/81043823" target="_blank" rel="noopener">https://blog.csdn.net/yuejisuo1948/article/details/81043823</a></li></ul></li><li><code>C/C++</code>: <a href="http://www.mingw.org/" target="_blank" rel="noopener">http://www.mingw.org/</a><ul><li>使用参考 <a href="https://www.cnblogs.com/iwideal/p/7647243.html" target="_blank" rel="noopener">https://www.cnblogs.com/iwideal/p/7647243.html</a></li></ul></li><li><code>Java8</code>: <a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></li><li><code>Node</code>: <a href="https://nodejs.org/zh-cn/" target="_blank" rel="noopener">https://nodejs.org/zh-cn/</a></li></ul><h1 id="IDE"><a href="#IDE" class="headerlink" title="IDE"></a>IDE</h1><ul><li><code>JetBrains (Pycharm, IntelliJ IDEA, DataGrip)</code>: <a href="http://www.jetbrains.com/" target="_blank" rel="noopener">http://www.jetbrains.com/</a></li><li><code>Visual Studio Community</code>: <a href="https://visualstudio.microsoft.com/vs/" target="_blank" rel="noopener">https://visualstudio.microsoft.com/vs/</a></li></ul><h1 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h1><ul><li><code>Git</code>: <a href="https://git-scm.com/" target="_blank" rel="noopener">https://git-scm.com/</a></li><li><code>FluentTerminal</code>: <a href="https://github.com/felixse/FluentTerminal" target="_blank" rel="noopener">https://github.com/felixse/FluentTerminal</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> technique </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Windows </tag>
            
            <tag> Software </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker部署ShareLaTeX并简单配置中文环境</title>
      <link href="/technique/Docker%E9%83%A8%E7%BD%B2ShareLaTeX%E5%B9%B6%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/"/>
      <url>/technique/Docker%E9%83%A8%E7%BD%B2ShareLaTeX%E5%B9%B6%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/sharelatex.png" alt=""></p><blockquote><p>由于某些原因，国内访问ShareLaTeX或Overleaf网站速度特别慢而且经常掉线，科研环境十分不友好，因此有了自己搭建ShareLaTeX服务打算，且其支持Docker容器化部署，安装过程比较容易。本文记录了在实验室内网环境下利用Docker搭建ShareLaTeX服务的过程，并进行中文环境配置。</p></blockquote><a id="more"></a><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>系统与Docker环境安装同上篇<a href="https://yxnchen.github.io/technique/Docker%E9%83%A8%E7%BD%B2GitLab%E5%B9%B6%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/">Docker部署GitLab并实现基本配置</a>，然后继续按照<a href="https://legacy.gitbook.com/book/yeasy/docker_practice/details" target="_blank" rel="noopener">教程</a>安装<code>docker-compose</code>组件。</p><h1 id="安装并配置ShareLaTeX"><a href="#安装并配置ShareLaTeX" class="headerlink" title="安装并配置ShareLaTeX"></a>安装并配置ShareLaTeX</h1><blockquote><p>由于ShareLaTeX的安装依赖于MongoDB和Redis，因此本文将使用官方向导建议使用<code>docker-compose</code>快速部署ShareLaTeX</p></blockquote><ul><li><p>拉取最新的ShareLaTeX镜像</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker pull sharelatex/sharelatex</span><br></pre></td></tr></table></figure></li><li><p>下载<code>docker-compose.yml</code>文件，并进行配置，见<a href="https://github.com/sharelatex/sharelatex/wiki/Quick-Start-Guide#using-a-compose-file" target="_blank" rel="noopener">Quick Start Guide</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ mkdir -p ~/sharelatex          <span class="comment"># 在用户目录下创建一个sharelatex文件夹</span></span><br><span class="line">$ <span class="built_in">cd</span> ~/sharelatex                <span class="comment"># 进入sharelatex文件夹</span></span><br><span class="line">$ curl -O https://raw.githubusercontent.com/sharelatex/sharelatex/master/docker-compose.yml                      <span class="comment"># 下载官方的docker-compose.yml配置文件</span></span><br><span class="line">$ sudo vi docker-compose.yml     <span class="comment"># 使用vi修改配置文件</span></span><br></pre></td></tr></table></figure></li><li><p>需要配置的项</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 避免端口重复</span></span><br><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="number">5000</span><span class="string">:80</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改本地挂载目录</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">/home/docker/sharelatex:/var/lib/sharelatex</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加升级texlive需要的环境变量，主要是添加2018目录到2017前面，目的是为了防止后面安装完整版texlive时出现错误</span></span><br><span class="line"><span class="attr">environment:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">PATH:</span> <span class="string">/usr/localsbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/texlive/2018/bin/x86_64-linux:/usr/local/texlive/2017/bin/x86_64-linux</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面选项设置ShareLaTeX的显示样式</span></span><br><span class="line"><span class="attr">SHARELATEX_APP_NAME:</span> <span class="string">Our</span> <span class="string">ShareLaTeX</span></span><br><span class="line"><span class="attr">SHARELATEX_NAV_TITLE:</span> <span class="string">Our</span> <span class="string">ShareLaTeX</span> <span class="string">Instance</span></span><br><span class="line"><span class="attr">SHARELATEX_HEADER_IMAGE_URL:</span> <span class="attr">http://somewhere.com/mylogo.png</span></span><br><span class="line"><span class="attr">SHARELATEX_LEFT_FOOTER:</span> <span class="string">'[&#123;"text": "Powered by &lt;a href=\"https://www.sharelatex.com\"&gt;ShareLaTeX&lt;/a&gt; 2016"&#125;,&#123;"text": "Another page I want to link to can be found &lt;a href=\"here\"&gt;here&lt;/a&gt;"&#125; ]'</span></span><br><span class="line"><span class="attr">SHARELATEX_RIGHT_FOOTER:</span> <span class="string">'[&#123;"text": "Hello I am on the Right"&#125; ]'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改mongo和redis的本地挂载目录</span></span><br><span class="line"><span class="comment"># mongo</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">/home/docker/mongo_data:/data/db</span></span><br><span class="line"><span class="comment"># redis</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">/home/docker/redis_data:/data</span></span><br></pre></td></tr></table></figure></li><li><p>创建并运行ShareLaTeX容器，启动后不要着急进入网站</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在sharelatex目录下</span></span><br><span class="line">$ docker-compose up -d</span><br></pre></td></tr></table></figure></li><li><p>升级并安装完整版texlive，<a href="https://www.tug.org/texlive/upgrade.html" target="_blank" rel="noopener">官方教程</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入容器的命令行（sharelatex容器本质上是一个Ubuntu）</span></span><br><span class="line">$ docker <span class="built_in">exec</span> -it sharelatex bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入texlive默认安装目录</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/texlive</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制2017文件夹为2018</span></span><br><span class="line">$ cp -a 2017 2018</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载并运行升级脚本</span></span><br><span class="line">$ wget http://mirror.ctan.org/systems/texlive/tlnet/update-tlmgr-latest.sh</span><br><span class="line">$ sh update-tlmgr-latest.sh -- --upgrade</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更换texlive的下载源，例如国内的清华源</span></span><br><span class="line">$ tlmgr option repository https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/tlnet/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 升级tlmgr</span></span><br><span class="line">$ tlmgr update --self --all</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新字体缓存（好像没成功，但是不影响下面操作）</span></span><br><span class="line">$ luaotfload-tool -fu</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装完整版texlive（漫长的等待，不要让shell断开）</span></span><br><span class="line">$ tlmgr install scheme-full</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推出sharelatex的命令行界面，并重启sharelatex容器</span></span><br><span class="line">$ <span class="built_in">exit</span></span><br><span class="line">$ docker restart sharelatex</span><br></pre></td></tr></table></figure></li><li><p>使用ShareLaTeX</p><p>进入浏览器访问<code>http://192.168.8.21:5000/launchpad</code>，根据提示创建Admin用户。</p></li></ul><h1 id="配置中文写作环境"><a href="#配置中文写作环境" class="headerlink" title="配置中文写作环境"></a>配置中文写作环境</h1><blockquote><p>下载的sharelatex镜像里面默认是没有安装xfont和中文字体的，因此无法渲染中文文档，必须安装所需的中文字体，这里以Windows下常用字体和Adobe Song Std为例。原教程见<a href="https://blog.csdn.net/hello_percy/article/details/72147414" target="_blank" rel="noopener">ArchLinux 部署ShareLaTex并且配置中文支持</a>。</p></blockquote><ul><li><p>将Windows字体库（即目录<code>C:\windows\fonts</code>）上传到host机，如果Windows安装了Git可以使用<code>scp</code>命令直接上传</p></li><li><p>在host机下把<code>fonts</code>目录打包并传到sharelatex容器中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入fonts目录</span></span><br><span class="line">$ <span class="built_in">cd</span> fonts/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除其中的.fon字体文件（该种格式文件在后面建立字体目录时会报错），只保留TrueType和OpenType字体，即.ttf和.otf</span></span><br><span class="line"><span class="comment"># 一般地，如果只需要其中特定的中文字体，只需要上传需要的字体即可</span></span><br><span class="line">$ rm -r *.fon</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回上层目录并打包</span></span><br><span class="line">$ <span class="built_in">cd</span> ..</span><br><span class="line">$ tar -zcvf winfonts.tar.gz fonts/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把压缩文件传到sharelatex容器的root目录下</span></span><br><span class="line">$ docker cp winfonts.tar.gz sharelatex:/root</span><br></pre></td></tr></table></figure></li><li><p>在容器中安装Windows字体</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入容器的命令行界面</span></span><br><span class="line">$ docker <span class="built_in">exec</span> -it sharelatex bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过安装wqy字体同时安装xfont工具</span></span><br><span class="line">$ apt-get install xfonts-wqy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入root目录，解压winfonts.tar.gz，并剪切到系统字体目录下</span></span><br><span class="line">$ <span class="built_in">cd</span> ~</span><br><span class="line">$ tar -zxvf winfonts.tar.gz</span><br><span class="line">$ mv winfonts /usr/share/fonts/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入字体目录安装字体</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/share/fonts/winfonts</span><br><span class="line">$ mkfontscale</span><br><span class="line">$ mkfontdir</span><br><span class="line">$ <span class="built_in">fc</span>-cache -fv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查确认中文字体安装成功</span></span><br><span class="line">$ <span class="built_in">fc</span>-list :lang=zh-cn</span><br></pre></td></tr></table></figure></li><li><p>回到ShareLaTeX网站，创建一个新项目，使用$C\TeX$宏集和XeLaTeX编译器，即可生成中文pdf。（详见<a href="http://mirrors.ibiblio.org/CTAN/language/chinese/ctex/ctex.pdf" target="_blank" rel="noopener">$C\TeX$宏集手册</a>）</p></li><li><p>因为学校论文的需要，有时需要其他中文字体，例如Adobe宋体，其安装流程与上述基本一致。（PS：在GitHub上可以找到公开的Adobe Song Std字体，涉及版权这里不放链接）</p></li></ul><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ol><li><a href="https://blog.csdn.net/sofair/article/details/80994960" target="_blank" rel="noopener">在本地部署ShareLatex服务</a></li><li><a href="https://haoyu.love/blog640.html" target="_blank" rel="noopener">本地部署 ShareLatex</a></li><li><a href="https://blog.csdn.net/hello_percy/article/details/72147414" target="_blank" rel="noopener">ArchLinux 部署ShareLaTex并且配置中文支持</a></li><li><a href="https://www.scaleway.com/docs/installing-sharelatex-ubuntu/" target="_blank" rel="noopener">Installing ShareLaTeX</a></li><li><a href="https://github.com/sharelatex/sharelatex/wiki/Quick-Start-Guide" target="_blank" rel="noopener">Quick Start Guide</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> technique </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tutorial </tag>
            
            <tag> Linux </tag>
            
            <tag> Docker </tag>
            
            <tag> ShareLaTeX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker部署GitLab并实现基本配置</title>
      <link href="/technique/Docker%E9%83%A8%E7%BD%B2GitLab%E5%B9%B6%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"/>
      <url>/technique/Docker%E9%83%A8%E7%BD%B2GitLab%E5%B9%B6%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/docker-build-push-gitlab-ci.png" alt=""></p><blockquote><p>本地GitLab的安装需要部署各种依赖和其他服务，费时且麻烦，而直接使用Docker进行容器化部署则省时简单，只要运行一行命令即可使用。本文记录了在实验室内网环境下利用Docker搭建源码托管工具GitLab，并列出一些必要的个性化配置项。</p></blockquote><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><p>由于Ubuntu系统在Docker环境下兼容性更高，选择了 <code>Ubuntu 18.04 LTS</code> 作为操作系统环境。</p><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><p>Docker环境的安装十分简单，在这里不详述，根据<a href="https://legacy.gitbook.com/book/yeasy/docker_practice/details" target="_blank" rel="noopener">Docker —— 从入门到实践</a>选择对应操作系统的安装教程即可。</p><h2 id="安装GitLab-ce"><a href="#安装GitLab-ce" class="headerlink" title="安装GitLab-ce"></a>安装GitLab-ce</h2><blockquote><p>GitLab的安装可以直接<code>run</code>，或者通过<code>docker-compose</code>文件指定安装流程，这里使用前者进行快速简单安装，后者后续更新。</p></blockquote><ul><li><p>拉取GitLab-ce镜像，查看镜像信息</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker pull gitlab/gitlab-ce</span><br><span class="line">$ docker image ls</span><br></pre></td></tr></table></figure></li><li><p>创建并启动一个GitLab容器，<code>:</code>后的内容不要修改</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ GITLAB_HOME = /home/docker/gitlab     <span class="comment"># 建立gitlab本地目录</span></span><br><span class="line">$ docker run -d \</span><br><span class="line">--hostname gitlab.example.com\          <span class="comment"># 指定容器域名,创建镜像仓库用</span></span><br><span class="line">-p 8443:443 \                           <span class="comment"># 容器443端口映射到主机8443端口(https)</span></span><br><span class="line">-p 8080:80 \                            <span class="comment"># 容器80端口映射到主机8080端口(http)</span></span><br><span class="line">-p 2222:22 \                            <span class="comment"># 容器22端口映射到主机2222端口(ssh)</span></span><br><span class="line">--name gitlab \                         <span class="comment"># 容器名称</span></span><br><span class="line">--restart always \                      <span class="comment"># 容器退出后自动重启</span></span><br><span class="line">-v <span class="variable">$GITLAB_HOME</span>/config:/etc/gitlab \    <span class="comment"># 挂载本地目录到容器配置目录</span></span><br><span class="line">-v <span class="variable">$GITLAB_HOME</span>/logs:/var/<span class="built_in">log</span>/gitlab \  <span class="comment"># 挂载本地目录到容器日志目录</span></span><br><span class="line">-v <span class="variable">$GITLAB_HOME</span>/data:/var/opt/gitlab \  <span class="comment"># 挂载本地目录到容器数据目录</span></span><br><span class="line">gitlab/gitlab-ce:latest                 <span class="comment"># 使用的镜像:版本</span></span><br></pre></td></tr></table></figure></li><li><p>查看容器运行情况，出现gitlab运行信息表明启动成功</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker container ls</span><br></pre></td></tr></table></figure></li><li><p>浏览器进入<code>http://192.168.8.21:8080</code>，使用<code>root</code>账户登录并设置密码即可进入管理员界面</p></li></ul><h2 id="配置GitLab"><a href="#配置GitLab" class="headerlink" title="配置GitLab"></a>配置GitLab</h2><blockquote><p>可参考官方配置说明<a href="https://docs.gitlab.com/omnibus/settings/configuration.html" target="_blank" rel="noopener">文档</a>，本地配置文件在<code>$GITLAB_HOME/config/gitlab.rb</code></p></blockquote><h3 id="备份默认配置文件"><a href="#备份默认配置文件" class="headerlink" title="备份默认配置文件"></a>备份默认配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/docker/gitlab/config</span><br><span class="line">$ cp gitlab.rb gitlab.rb.default</span><br></pre></td></tr></table></figure><h3 id="修改与重载配置"><a href="#修改与重载配置" class="headerlink" title="修改与重载配置"></a>修改与重载配置</h3><ul><li><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ sudo vi /home/docker/gitlab/config</span><br></pre></td></tr></table></figure></li><li><p>重载配置</p><p>在gitlab容器内重载</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -t gitlab gitlab-ctl reconfigure</span><br><span class="line">$ docker <span class="built_in">exec</span> -t gitlab gitlab-ctl restart</span><br></pre></td></tr></table></figure><p>或直接重启容器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker restart gitlab</span><br></pre></td></tr></table></figure></li></ul><h3 id="常用配置选项"><a href="#常用配置选项" class="headerlink" title="常用配置选项"></a>常用配置选项</h3><ul><li><p>配置web请求地址</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">external_url &apos;http://192.168.8.21&apos;</span><br></pre></td></tr></table></figure></li><li><p>设置时区</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitlab_rails[&apos;time_zone&apos;] = &apos;Asia/Shanghai&apos;</span><br></pre></td></tr></table></figure></li><li><p>允许自定义头像，去掉注释<code>#</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitlab_rails[&apos;gravatar_plain_url&apos;] = &apos;http://www.gravatar.com/avatar/%&#123;hash&#125;?s=%&#123;size&#125;&amp;d=identicon&apos;</span><br></pre></td></tr></table></figure></li><li><p>由于设置了端口映射，设置如下选项使得网页端显示正常可用的ssh地址，如“ssh://git@192.168.8.21:2222/xxx/xxx.git”</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 2222</span><br></pre></td></tr></table></figure></li><li><p>在实验室内网环境下，关闭GitLab的CI/CD功能，详细见<a href="https://docs.gitlab.com/ce/ci/enable_or_disable_ci.html" target="_blank" rel="noopener">官方说明</a></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitlab_rails[&apos;gitlab_default_projects_features_builds&apos;] = false</span><br></pre></td></tr></table></figure></li><li><p>设置GitLab备份路径</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitlab_rails[&apos;manage_backup_path&apos;] = true</span><br><span class="line">gitlab_rails[&apos;backup_path&apos;] = &quot;/var/opt/gitlab/backups&quot;</span><br></pre></td></tr></table></figure></li><li><p>配置邮箱服务，可以参考<a href="http://blog.51cto.com/8456082/2090423" target="_blank" rel="noopener">连接</a></p></li><li><p>添加SSL证书支持HTTPS，可以参考<a href="https://blog.csdn.net/u014258541/article/details/79224492/" target="_blank" rel="noopener">连接</a>，由于使用自签名证书Chrome会拦截，所以没有弄</p></li></ul><h2 id="更新GitLab"><a href="#更新GitLab" class="headerlink" title="更新GitLab"></a>更新GitLab</h2><ul><li><p>拉取最新的GitLab-ce镜像，然后停止并删除当前的GitLab容器</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker stop gitlab</span><br><span class="line">$ docker rm gitlab</span><br></pre></td></tr></table></figure></li><li><p>重启创建并启动GitLab容器，使用同样的配置和volume参数即可，GitLab会自动读取这些配置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker run -d \</span><br><span class="line">--hostname gitlab.example.com\</span><br><span class="line">-p 8443:443 \ </span><br><span class="line">-p 8080:80 \ </span><br><span class="line">-p 2222:22 \</span><br><span class="line">--name gitlab \</span><br><span class="line">--restart always \</span><br><span class="line">-v <span class="variable">$GITLAB_HOME</span>/config:/etc/gitlab \</span><br><span class="line">-v <span class="variable">$GITLAB_HOME</span>/logs:/var/<span class="built_in">log</span>/gitlab \</span><br><span class="line">-v <span class="variable">$GITLAB_HOME</span>/data:/var/opt/gitlab \</span><br><span class="line">gitlab/gitlab-ce:latest</span><br></pre></td></tr></table></figure></li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="http://blog.51cto.com/8456082/2090423" target="_blank" rel="noopener">通过docker安装Gitlab</a></li><li><a href="https://www.cnblogs.com/int32bit/p/5310382.html" target="_blank" rel="noopener">使用Docker部署Gitlab</a></li><li><a href="https://blog.csdn.net/u014258541/article/details/79224492/" target="_blank" rel="noopener">docker部署gitLab</a></li><li><a href="https://docs.gitlab.com/ce/ci/enable_or_disable_ci.html" target="_blank" rel="noopener">How to enable or disable GitLab CI/CD</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> technique </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tutorial </tag>
            
            <tag> Linux </tag>
            
            <tag> Docker </tag>
            
            <tag> GitLab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>贝叶斯泊松分解变分推断笔记</title>
      <link href="/research/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%8A%E6%9D%BE%E5%88%86%E8%A7%A3%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD%E7%AC%94%E8%AE%B0/"/>
      <url>/research/%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%8A%E6%9D%BE%E5%88%86%E8%A7%A3%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="贝叶斯泊松分解"><a href="#贝叶斯泊松分解" class="headerlink" title="贝叶斯泊松分解"></a>贝叶斯泊松分解</h2><h3 id="一般形式"><a href="#一般形式" class="headerlink" title="一般形式"></a>一般形式</h3><p>因为可以对观测数据进行灵活的符合实际的建模（不同的概率分布假设），贝叶斯概率分解模型已经成为了最常见的矩阵/张量分解方法。其中，贝叶斯泊松分解模型一方面可以对计数值（count data）进行有效的建模，另一方面得益于其非负的分解结构，可以用于替代传统的非负矩阵分解模型（NMF），因而被广泛应用于推荐系统、因子分析和聚类分析中。常见的贝叶斯泊松矩阵分解模型如下，其中观测值$x_{ij}$服从泊松分布，而其分解得到的因子矩阵的值则服从共轭的Gamma分布：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}&x_{ij}=\sum_{k=1}^{K}z_{ijk}, z_{ijk}\sim\text{Pois}(u_{ik}v_{jk}), \\&u_{ik}\sim\text{Gamma}(a^{(u)},\frac{b^{(u)}}{a^{(u)}}),\\&v_{jk}\sim\text{Gamma}(a^{(v)},\frac{b^{(v)}}{a^{(v)}}).\\\end{split}\end{equation}</script><a id="more"></a><p>其中Gamma分布的概率密度函数如下所示，$\alpha\in\mathbb{R}<em>{+}$为shape参数，$\beta\in\mathbb{R}</em>{+}$为scale参数，$\Gamma(n+1)=n!$为gamma函数：</p><script type="math/tex; mode=display">\begin{equation}\text{Gamma}(x;\alpha,\beta)=\text{exp}\left((\alpha-1)\text{ln}x-\frac{x}{\beta}-\text{ln}\Gamma(\alpha)-\alpha\text{ln}\beta\right)\end{equation}</script><h3 id="Binary形式"><a href="#Binary形式" class="headerlink" title="Binary形式"></a>Binary形式</h3><h2 id="变分推断"><a href="#变分推断" class="headerlink" title="变分推断"></a>变分推断</h2><h3 id="变分更新公式"><a href="#变分更新公式" class="headerlink" title="变分更新公式"></a>变分更新公式</h3><p>上述模型的联合概率分布函数为</p><script type="math/tex; mode=display">\begin{equation}p(X,Z,U,V)=p(X\mid Z)p(Z\mid U,V)p(U)p(V)\end{equation}</script><p>其对数形式展开如下</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\text{ln}p(X,Z,U,V)=&\sum_{i}\sum_{j}\sum_{k}\left(-u_{ik}v_{jk}+z_{ijk}\text{ln}(u_{ik}v_{jk})-\text{ln}\Gamma(z_{ijk}+1)\right) \\&+\sum_{i}\sum_{j}\left((a^{(u)}-1)\text{ln}u_{ik}-\frac{a^{(u)}}{b^{(u)}}u_{ik}-\text{ln}\Gamma(a^{(u)})-a^{(u)}\text{ln}\frac{b^{(u)}}{a^{(u)}}\right) \\&+\sum_{i}\sum_{j}\left((a^{(v)}-1)\text{ln}v_{jk}-\frac{a^{(v)}}{b^{(v)}}v_{jk}-\text{ln}\Gamma(a^{(v)})-a^{(v)}\text{ln}\frac{b^{(v)}}{a^{(v)}}\right) \\\end{split}\end{equation}</script><p>与此同时，对后验概率分布的变分近似分布进行分解，得到</p><script type="math/tex; mode=display">\begin{equation}\begin{split}q(Z,U,V)&=q(Z)q(U)q(V) \\&=\prod_{i,j}q_{\boldsymbol{z}_{ij}}(\boldsymbol{z}_{ij})\prod_{i,k}q_{u_{ik}}(u_{ik})\prod_{j,k}q_{v_{jk}}(v_{jk})\end{split}\end{equation}</script><p>根据<a href="https://yxnchen.github.io/machine-learning/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD%E7%AC%94%E8%AE%B0/">变分贝叶斯推断笔记</a>中的公式(3)，我们可以对各个因子的最优化形式进行推导。首先，对于因子$q<em>{\boldsymbol{z}</em>{ij}}(\boldsymbol{z}_{ij})$，有</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\text{ln}q_{\boldsymbol{z}_{ij}}^{*}(\boldsymbol{z}_{ij})&=\mathbb{E}_{(\Theta\backslash \boldsymbol{z}_{ij})}[\text{ln}p(X,Z,U,V)]+\text{const} \\&=\mathbb{E}_{(\Theta\backslash \boldsymbol{z}_{ij})}\left[\sum_{k}\left(-\text{ln}\Gamma(z_{ijk}+1)+z_{ijk}\left(\text{ln}u_{ik}+\text{ln}v_{jk}\right)\right)\right]+\text{const} \\&=\sum_{k}\left(-\text{ln}\Gamma(z_{ijk}+1)+z_{ijk}\left(\mathbb{E}[\text{ln}u_{ik}]+\mathbb{E}[\text{ln}v_{jk}]\right)\right)+\text{const} \\&=\sum_{k}\left(-\text{ln}\Gamma(z_{ijk}+1)+z_{ijk}\text{ln}e^{\mathbb{E}[\text{ln}u_{ik}]+\mathbb{E}[\text{ln}v_{jk}]}\right)+\text{const} \\\end{split}\end{equation}</script><p>辅助变量$\boldsymbol{z}_{ij}$的后验为多项式分布，其参数为</p><script type="math/tex; mode=display">\begin{equation}\phi_{ijk}^{*}=\frac{e^{\mathbb{E}[\text{ln}u_{ik}]+\mathbb{E}[\text{ln}v_{jk}]}}{\sum_{k}e^{\mathbb{E}[\text{ln}u_{ik}]+\mathbb{E}[\text{ln}v_{jk}]}}\end{equation}</script><p>因此$z_{ijk}$的更新公式为</p><script type="math/tex; mode=display">\begin{equation}\mathbb{E}[z_{ijk}]=x_{ij}\phi_{ijk}^{*}\end{equation}</script><p>进一步地，对于因子$q<em>{u</em>{ik}}(u_{ik})$，有</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\text{ln}q_{u_{ik}}^{*}(u_{ik})&=\mathbb{E}_{(\Theta\backslash u_{ik})}[\text{ln}p(X,Z,U,V)]+\text{const} \\&=\mathbb{E}_{(\Theta\backslash u_{ik})}\left[\left(a^{(u)}+\sum_{j}z_{ijk}-1\right)\text{ln}u_{ik}-\left(\frac{a^{(u)}}{b^{(u)}}+\sum_{k}v_{jk}\right)u_{ik}\right]+\text{const} \\&=\left(a^{(u)}+\sum_{j}\mathbb{E}[z_{ijk}]-1\right)\text{ln}u_{ik}-\left(\frac{a^{(u)}}{b^{(u)}}+\sum_{k}\mathbb{E}[v_{jk}]\right)u_{ik}+\text{const} \\\end{split}\end{equation}</script><p>由共轭性，$q<em>{u</em>{ik}}(u_{ik})$仍然是Gamma分布，其参数为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\alpha_{ik}^{(u)*}&=a^{(u)}+\sum_{j}\mathbb{E}[z_{ijk}],\\\beta_{ik}^{(u)*}&=\left(\frac{a^{(u)}}{b^{(u)}}+\sum_{k}\mathbb{E}[v_{jk}]\right)^{-1},\\\end{split}\end{equation}</script><p>因此$u_{ik}$的更新公式为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathbb{E}[u_{ik}]&=\alpha_{ik}^{(u)*}\beta_{ik}^{(u)*} \\\mathbb{E}[\text{ln}u_{ik}]&=\psi(\alpha_{ik}^{(u)*})+\text{ln}\beta_{ik}^{(u)*}\end{split}\end{equation}</script><p>最后，因子$q<em>{v</em>{jk}}(v<em>{jk})$的计算与因子$q</em>{u<em>{ik}}(u</em>{ik})$类似。</p><h3 id="变分下界计算"><a href="#变分下界计算" class="headerlink" title="变分下界计算"></a>变分下界计算</h3><p>变分下界的计算公式如下：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathcal{L}(q)&=\mathbb{E}_{q}[\text{ln}p(X,\Theta)]+H(q(\Theta))\end{split}\end{equation}</script><p>其中$H(q(\Theta))=-\mathbb{E}<em>{q}[\text{ln}q(\Theta)]$，因此我们可以计算变分下界，其中$\sum</em>{i}\sum<em>{j}\sum</em>{k}\mathbb{E}\left[\text{ln}\Gamma(z_{ijk}+1)\right]$项可以在计算过程中消去</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathcal{L}(q)=&-\sum_{i}\sum_{j}\sum_{k}\mathbb{E}[u_{ik}]\mathbb{E}[v_{jk}] \\&+\sum_{i}\sum_{k}\mathbb{E}[\text{ln}u_{ik}]\left(a^{(u)}-1+\sum_{j}\mathbb{E}[z_{ijk}]\right) \\&+\sum_{j}\sum_{k}\mathbb{E}[\text{ln}v_{jk}]\left(a^{(v)}-1+\sum_{i}\mathbb{E}[z_{ijk}]\right) \\&+\sum_{i}\sum_{k}\left(-\frac{a^{(u)}}{b^{(u)}}\mathbb{E}[u_{ik}]-\text{ln}\Gamma(a^{(u)})-a^{(u)}\text{ln}\frac{b^{(u)}}{a^{(u)}}\right) \\&+\sum_{j}\sum_{k}\left(-\frac{a^{(v)}}{b^{(v)}}\mathbb{E}[v_{jk}]-\text{ln}\Gamma(a^{(v)})-a^{(v)}\text{ln}\frac{b^{(v)}}{a^{(v)}}\right) \\&+\sum_{i}\sum_{j}\left(-\text{ln}\Gamma(x_{ij}+1)-\sum_{k}\mathbb{E}[z_{ijk}]\text{ln}\phi_{ijk}^{*}\right) \\&+\sum_{i}\sum_{k}\left(-(\alpha_{ik}^{(u)*}-1)\psi(\alpha_{ik}^{(u)*})+\text{ln}\beta_{ik}^{(u)*}+\alpha_{ik}^{(u)*}+\text{ln}\Gamma(\alpha_{ik}^{(u)*})\right) \\&+\sum_{j}\sum_{k}\left(-(\alpha_{jk}^{(v)*}-1)\psi(\alpha_{jk}^{(v)*})+\text{ln}\beta_{jk}^{(v)*}+\alpha_{jk}^{(v)*}+\text{ln}\Gamma(\alpha_{jk}^{(v)*})\right) \\\end{split}\end{equation}</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Prem Gopalan, Jake M. Hofman, David M. Blei. “Scalable recommendation with hierarchical poisson factorization”. In <em>UAI</em>, 2015.</li></ol>]]></content>
      
      
      <categories>
          
          <category> research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Bayesian </tag>
            
            <tag> Variational Inference </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>变分贝叶斯推断笔记</title>
      <link href="/research/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD%E7%AC%94%E8%AE%B0/"/>
      <url>/research/%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%8E%A8%E6%96%AD%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="变分贝叶斯推断"><a href="#变分贝叶斯推断" class="headerlink" title="变分贝叶斯推断"></a>变分贝叶斯推断</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>假设当前有一个贝叶斯模型，且其中的参数都有相应的先验分布。同时，模型中还可能有潜变量，将其与各种参数标记为$\Theta$。同样地，把所有观测变量集合标记为$\mathcal{Y}$。因此，我们希望找到分布$q(\Theta)$来逼近真实后验分布$p(\Theta\mid\mathcal{Y})$，而这可以通过最小化KL散度实现，也即：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\text{KL}(q(\Theta)\|p(\Theta|\mathcal{Y}))&=\int q(\Theta)\text{ln}\left\{\frac{q(\Theta)}{p(\Theta\mid\mathcal{Y})}\right\}d\Theta \\&=\text{ln}p(\mathcal{Y})-\int q(\Theta)\text{ln}\left\{\frac{p(\mathcal{Y},\Theta)}{q(\Theta)}\right\}d\Theta\end{split}\end{equation}</script><p>其中$\text{ln}p(\mathcal{Y})$表示模型证据（Evidence），则其下界（lower bound）可以定义为$\mathcal{L}(q)=\int q(\Theta)\text{ln}{\frac{p(\mathcal{Y},\Theta)}{q(\Theta)}}d\Theta$。因为模型证据是一个常量，当KL散度为0时，下界出现最大值，这就意味着$q(\Theta)=p(\mathcal{Y},\Theta)$。<br><a id="more"></a></p><h3 id="平均场理论"><a href="#平均场理论" class="headerlink" title="平均场理论"></a>平均场理论</h3><p>根据平均场理论（mean field theory），我们假设变分分布$q(\Theta)$可以被分解成各组变量分布的乘积，即可以写作：</p><script type="math/tex; mode=display">\begin{equation}q(\Theta)=\prod_{j}^{M}q_j(\Theta_j)\end{equation}</script><p>这是针对该分布的唯一假设，其中每一个独立因子$q_j(\Theta_j)$的特定函数形式可以具体地一个个推导出来。通过最大化下届$\mathcal{L}(q)$，第$j$个因子的优化形式由下式给出：</p><script type="math/tex; mode=display">\begin{equation}\text{ln}q_j(\Theta_j)=\mathbb{E}_{q(\Theta\backslash\Theta_j)}\left[\text{ln}p(\mathcal{Y},\Theta)\right]+\text{const}\end{equation}</script><p>其中$\mathbb{E}_{q(\Theta\backslash\Theta_j)}\left[\cdot\right]$表示关于除$\Theta_j$外所有变量的$q$分布的期望。因为所有参数的分布都属于指数族分布，且都与其父节点共轭，因此我们能够通过公式(3)推导出$\Theta$中每个参数的后验分布更新的近似形式。</p><h3 id="变分下界"><a href="#变分下界" class="headerlink" title="变分下界"></a>变分下界</h3><p>在模型计算时，可以通过直接计算变分下界$\mathcal{L}(q)$来判断算法是否收敛，因为在每一次迭代中变分下界不减。变分下界可以通过下式进行计算</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathcal{L}(q)&=\int q(\Theta)\text{ln}\left\{\frac{p(\mathcal{Y},\Theta)}{p(\Theta)}\right\}d\Theta \\&=\mathbb{E}_{q}[\text{ln}p(\mathcal{Y},\Theta)]-\mathbb{E}_{q}[\text{ln}q(\Theta)] \\&=\mathbb{E}_{q}[\text{ln}p(\mathcal{Y}\mid\Theta)]+\mathbb{E}_{q}[\text{ln}p(\Theta)]-\sum_{j}\mathbb{E}_{q_j(\Theta_j)}[\text{ln}q_j(\Theta_j)]\end{split}\end{equation}</script><p>其中第一项表示联合分布的后验期望，而第二项则表示后验$q$分布的熵$H(q(\Theta))=-\mathbb{E}_{q}[\text{ln}p(q(\Theta))]$。</p><h2 id="例子-一元高斯模型"><a href="#例子-一元高斯模型" class="headerlink" title="例子-一元高斯模型"></a>例子-一元高斯模型</h2><h3 id="模型推断"><a href="#模型推断" class="headerlink" title="模型推断"></a>模型推断</h3><p>给定一组观测数据值$\mathcal{D}={x_1,x_2,\dots,x_N}$，假定数据是独立地从高斯分布中抽取的，目标是通过最大化后验分布推断得到均值参数$\mu$和精度参数$\tau$，其似然函数为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}p(\mathcal{D}\mid \mu,\tau)&=\prod_{i=1}^{N}\left(\frac{\tau}{2\pi}\right)^{\frac{1}{2}}\text{exp}\left\{-\frac{\tau(x_i-\mu)^2}{2}\right\} \\&=\left(\frac{\tau}{2\pi}\right)^{\frac{N}{2}}\text{exp}\left\{-\frac{\tau}{2}\sum_{i=1}^{N}(x_i-\mu)^2\right\}\end{split}\end{equation}</script><p>同时引入参数$\mu$和$\tau$的共轭先验分布，其形式为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}p(\mu\mid\tau)&= \mathcal{N}(\mu\mid\mu_{0},\left[\lambda_{0}\tau\right]^{-1})\\p(\tau)&= \text{Gam}(\tau\mid a_0,b_0)\end{split}\end{equation}</script><p>则其联合分布可以表示为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}p(\mathcal{D},\mu,\tau)=p(\mathcal{D}\mid\mu,\tau)p(\mu\mid\tau)p(\tau)\end{split}\end{equation}</script><p>对后验概率分布的变分近似进行分解</p><script type="math/tex; mode=display">\begin{equation}q(\mu,\tau)=q_{\mu}(\mu)q_{\tau}(\tau)\end{equation}</script><p>根据公式(3)，可以推导出各个因子的优化形式，对于$q_{\mu}(\mu)$，我们有</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\text{ln}q_{\mu}^{*}(\mu)&=\mathbb{E}_{\tau}[\text{ln}p(\mathcal{D}\mid\mu,\tau)+\text{ln}p(\mu\mid\tau)]+\text{const} \\&=-\frac{\mathbb{E}[\tau]}{2}\left\{\sum_{i=1}^{N}(x_i-\mu)^2+\lambda_0(\mu-\mu_0)^2\right\}+\text{const} \\&=-\frac{1}{2}\left\{(\lambda_0+N)\mathbb{E}[\tau]\mu^2-2(\lambda_0\mu_0+N\bar{x})\mathbb{E}[\tau]\mu\right\}+\text{const}\end{split}\end{equation}</script><p>由共轭性，可以看到$q_{\mu}(\mu)$是一个高斯分布，其参数为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\lambda^{*}&=(\lambda_0+N)\mathbb{E}[\tau] \\\mu^{*}&=[\lambda^*]^{-1}(\lambda_0\mu_0+N\bar{x})\mathbb{E}[\tau] =\frac{\lambda_0\mu_0+N\bar{x}}{\lambda_0+N}\end{split}\end{equation}</script><p>同理，因子$q_{\tau}(\tau)$的最优形式为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\text{ln}q_{\tau}^{*}(\tau)&=\mathbb{E}_{\mu}[\text{ln}p(\mathcal{D}\mid\mu,\tau)+\text{ln}p(\mu\mid\tau)+\text{ln}p(\tau)]+\text{const} \\&=(a_0-1+\frac{N+1}{2})\text{ln}\tau-\left\{b_0+\frac{1}{2}\mathbb{E}\mu\left[\sum_{i=1}^{N}(x_i-\mu)^2+\lambda_0(\mu-\mu_0)^2\right]\right\}\tau+\text{const}\end{split}\end{equation}</script><p>因此$q_{\tau}(\tau)$是一个Gamma分布，参数为</p><script type="math/tex; mode=display">\begin{equation}\begin{split}a^{*}&=a_0+\frac{N+1}{2} \\b^{*}&=b_0+\frac{1}{2}\mathbb{E}\mu\left[\sum_{i=1}^{N}(x_i-\mu)^2+\lambda_0(\mu-\mu_0)^2\right]\end{split}\end{equation}</script><p>为了评估模型的收敛性，我们进一步计算变分下界，其公式如下</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathcal{L}(q)&=\mathbb{E}_{q}[\text{ln}p(\mathcal{Y},\Theta)]-\mathbb{E}_{q}[\text{ln}q(\Theta)] \\&=\mathbb{E}_{q(\mu,\tau)}[\text{ln}p(\mathcal{D}\mid\mu,\tau)]+\mathbb{E}_{q(\mu,\tau)}[\text{ln}p(\mu\mid\tau)]+\mathbb{E}_{q(\tau)}[\text{ln}p(\tau)]-\mathbb{E}_{q(\mu)}[\text{ln}q(\mu)]-\mathbb{E}_{q(\tau)}[\text{ln}q(\tau)]\end{split}\end{equation}</script><p>上式各个部分可以通过下面公式计算得到，其中$\mathbb{E}<em>q[\mu^2]=\mathbb{E}</em>{\mu}[\mu^2]=(\mathbb{E}[\mu])^2+\text{Var}[\mu]$，$\mathbb{E}<em>q[\text{ln}\tau]=\mathbb{E}</em>{\tau}[\text{ln}\tau]=\psi(a)-\text{ln}b$，$\psi(\cdot)$为双伽马函数（digamma function）而$\Gamma(\cdot)$为伽马函数。</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathbb{E}_{q}[\text{ln}p(\mathcal{D}\mid\mu,\tau)]&=-\frac{N}{2}\text{ln}(2\pi)+\frac{N}{2}\mathbb{E}_q[\text{ln}\tau]-\frac{1}{2}\mathbb{E}_q[\tau]\mathbb{E}_q[\sum_{i=1}^{N}(x_i-\mu)^2] \\&=-\frac{N}{2}\text{ln}(2\pi)+\frac{N}{2}(\psi(a^*)-\text{ln}(b^*))-\frac{a^*}{2b^*}\left\{\sum_{i=1}^{N}x_i^2-2\mu^*\sum_{i=1}^{N}x_i+\mathbb{E}_q[\mu^2]\right\} \\\end{split}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathbb{E}_{q}[\text{ln}p(\mu\mid\tau)]&=-\frac{1}{2}\text{ln}(2\pi)+\frac{1}{2}\mathbb{E}_q[\text{ln}(\lambda_0\tau)]-\frac{\lambda_0}{2}\mathbb{E}_q[\tau]\mathbb{E}_q[(\mu-\mu_0)^2] \\&=-\frac{1}{2}\text{ln}(2\pi)+\frac{\text{ln}\lambda_0}{2}+\frac{1}{2}(\psi(a^*)-\text{ln}(b^*))-\frac{\lambda_0 a^*}{2b^*}\left\{\mathbb{E}_q[\mu^2]-2\mu_0\mu^*+\mu_0^2\right\} \\\end{split}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathbb{E}_{q}[\text{ln}p(\tau)]&=-\text{ln}\Gamma(a_0)+a_0\text{ln}b_0+(a_0-1)\mathbb{E}_q[\text{ln}\tau]-b_0\mathbb{E}_q[\tau] \\&=-\text{ln}\Gamma(a_0)+a_0\text{ln}b_0+(a_0-1)(\psi(a^*)-\text{ln}b^*)-b_0\frac{a^*}{b^*}\end{split}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}\begin{split}-\mathbb{E}_{q}[\text{ln}q(\mu)]&=\frac{1}{2}\text{ln}(2\pi)-\frac{\text{ln}\lambda^*}{2}+\frac{\lambda^*}{2}\left\{\mathbb{E}_q[\mu^2]-2(\mu^*)^2+(\mu^*)^2\right\} \\&=\frac{1}{2}\text{ln}(2\pi)-\frac{\text{ln}\lambda^*}{2}+\frac{1}{2}\end{split}\end{equation}</script><script type="math/tex; mode=display">\begin{equation}\begin{split}-\mathbb{E}_{q}[\text{ln}q(\tau)]&=\text{ln}\Gamma(a^*)-(a^*-1)\psi(a^*)-\text{ln}b^*+a^*\end{split}\end{equation}</script><p>至此，我们得到了关于参数$\mu$与$\tau$最优分布的表达式，且各自依赖于另一个分布的计算所得的一阶矩或二阶矩。因此通过初始化参数的值，可以通过不断迭代计算出后验分布。</p><p>在此例子中，由于模型简单且参数数量只有两个，因此我们可以通过直接求解上式的因子找到显示解。首先我们可以通过设置无信息先验（noninformative prior）来简化上述表达式，也即$\mu_0=\lambda_0=a_0=b_0=0$。根据Gamma分布的均值计算公式，我们有</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\frac{1}{\mathbb{E}[\tau]}=\frac{b^*}{a^*}=\mathbb{E}\left[\frac{1}{N+1}\sum_{i=1}^{N}(x_i-\mu)^2\right]=\frac{N}{N+1}(\overline{x^{2}}-2\bar{x}\mathbb{E}[\mu]+\mathbb{E}[\mu^2])\end{split}\end{equation}</script><p>由公式(10)，我们可以获得近似分布$q_\mu(\mu)$的一阶矩与二阶矩</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\mathbb{E}[\mu]=\bar{x}, \mathbb{E}[\mu^2]=\bar{x}^2+\frac{1}{N\mathbb{E}[\tau]}\end{split}\end{equation}</script><p>将其代入公式(19)，可以解出$\mathbb{E}[\tau]$</p><script type="math/tex; mode=display">\begin{equation}\frac{1}{\mathbb{E}[\tau]}=\overline{x^2}-\bar{x}^2\end{equation}=\frac{1}{N}\sum_{i=1}^{N}(x_i-\bar{x})^2</script><h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p>上节一元高斯的求解MATLAB代码如下所示，首先通过随机数生成器生成$N$个高斯分布的随机数作为模型观测值<br><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear;</span><br><span class="line"><span class="comment">% 生成高斯分布随机数</span></span><br><span class="line">mu_real = <span class="number">1</span>;</span><br><span class="line">tau_real = <span class="number">1.5</span>;</span><br><span class="line">N = <span class="number">200</span>;</span><br><span class="line">D = normrnd(mu_real, <span class="built_in">sqrt</span>(<span class="number">1.</span>/tau_real), [N,<span class="number">1</span>]);</span><br><span class="line">sumD = sum(D);</span><br><span class="line">sumD2 = sum(D.^<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">mu_est = mean(D); <span class="comment">% 公式(20)</span></span><br><span class="line">tau_est = <span class="number">1.</span>/(mean(D.^<span class="number">2</span>)-mean(D).^<span class="number">2</span>); <span class="comment">% 公式(21)</span></span><br><span class="line"><span class="comment">% 查看该一元高斯的分布图像</span></span><br><span class="line">x_real=<span class="number">-4</span>+mu_real:<span class="number">0.1</span>:mu_real+<span class="number">4</span>;</span><br><span class="line">y_real=normpdf(x_real,mu_real,<span class="built_in">sqrt</span>(<span class="number">1.</span>/tau_real));</span><br><span class="line">x_est=<span class="number">-4</span>+mu_est:<span class="number">0.1</span>:mu_est+<span class="number">4</span>;</span><br><span class="line">y_est=normpdf(x_est,mu_est,<span class="built_in">sqrt</span>(<span class="number">1.</span>/tau_est));</span><br><span class="line">figure;plot(x_real,y_real,<span class="string">'-r.'</span>,x_est,y_est,<span class="string">'--b.'</span>);grid;</span><br></pre></td></tr></table></figure></p><p>初始化模型参数和超参数<br><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 初始化参数和超参数</span></span><br><span class="line">mu0 = <span class="number">1e-6</span>; <span class="comment">% 无信息先验</span></span><br><span class="line">lambda0 = <span class="number">1e-6</span>; <span class="comment">% 无信息先验</span></span><br><span class="line">a0 = <span class="number">1e-6</span>; <span class="comment">% 无信息先验</span></span><br><span class="line">b0 = <span class="number">1e-6</span>; <span class="comment">% 无信息先验</span></span><br><span class="line">mu = <span class="built_in">randn</span>();</span><br><span class="line">mus(<span class="number">1</span>) = mu;</span><br><span class="line">tau = <span class="built_in">rand</span>();</span><br><span class="line">taus(<span class="number">1</span>) = tau;</span><br><span class="line"></span><br><span class="line">LB = <span class="number">0</span>; <span class="comment">% 变分下界</span></span><br><span class="line">tol = <span class="number">1e-5</span>; <span class="comment">% 收敛允许误差</span></span><br><span class="line">maxiters = <span class="number">100</span>; <span class="comment">% 迭代最大次数</span></span><br></pre></td></tr></table></figure></p><p>可视化求解过程，将分别绘出模型参数的真值与估计值比较图、变分下界变化图和精度参数$\tau$的后验分布变化图<br><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 可视化求解过程</span></span><br><span class="line">scrnsz = get(<span class="number">0</span>,<span class="string">'ScreenSize'</span>);</span><br><span class="line">h = figure(<span class="string">'Position'</span>,[scrnsz(<span class="number">3</span>)*<span class="number">0.25</span> scrnsz(<span class="number">4</span>)*<span class="number">0.25</span> scrnsz(<span class="number">3</span>)*<span class="number">0.5</span> scrnsz(<span class="number">4</span>)*<span class="number">0.5</span>]);</span><br><span class="line">set(<span class="number">0</span>,<span class="string">'CurrentFigure'</span>,h);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>); plot(mu_real, <span class="string">'-r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span> ); title(<span class="string">'Model parameter \mu'</span>); xlabel(<span class="string">'Iteration'</span>); grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>); plot(tau_real, <span class="string">'-r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span> ); title(<span class="string">'Model parameter \tau'</span>); xlabel(<span class="string">'Iteration'</span>); grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>); plot(LB, <span class="string">'-r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span> ); title(<span class="string">'Lower bound'</span>); xlabel(<span class="string">'Iteration'</span>); grid on;</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>); plot(<span class="number">0</span>:<span class="number">0.1</span>:<span class="number">20</span>, gampdf(<span class="number">0</span>:<span class="number">0.1</span>:<span class="number">20</span>, a0, <span class="number">1.</span>/b0), <span class="string">'r-'</span>); title(<span class="string">'Posterior pdf'</span>); xlabel(<span class="string">'Noise precision \tau'</span>); grid on;</span><br><span class="line">set(findall(h,<span class="string">'type'</span>,<span class="string">'text'</span>),<span class="string">'fontSize'</span>,<span class="number">12</span>);</span><br><span class="line">drawnow;</span><br></pre></td></tr></table></figure></p><p>模型迭代求解<br><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 模型求解</span></span><br><span class="line"><span class="keyword">for</span> it=<span class="number">1</span>:maxiters</span><br><span class="line">    <span class="comment">% 更新参数 mu，公式(10)</span></span><br><span class="line">    lambda_new = (lambda0+N)*tau;</span><br><span class="line">    mu_new = (<span class="number">1.</span>/lambda_new)*(lambda0*mu0+sumD)*tau;</span><br><span class="line">    mu = mu_new;</span><br><span class="line">    mus(it+<span class="number">1</span>) = mu;</span><br><span class="line">    E_mu2 = mu_new^<span class="number">2</span>+<span class="number">1.</span>/lambda_new; <span class="comment">% E[mu^2]=E[mu]^2+Var[mu]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 更新参数 tau，公式(12)</span></span><br><span class="line">    a_new = a0+(N+<span class="number">1</span>)./<span class="number">2</span>;</span><br><span class="line">    b_new = b0+<span class="number">0.5</span>*(sumD2<span class="number">-2</span>*(sumD+lambda0*mu0)*mu+(N+lambda0)*E_mu2+lambda0*(mu0^<span class="number">2</span>));</span><br><span class="line">    tau = a_new./b_new;</span><br><span class="line">    taus(it+<span class="number">1</span>) = tau;</span><br><span class="line">    E_lntau = <span class="built_in">psi</span>(a_new)-safelog(b_new); <span class="comment">% E[ln(tau)]=psi(a)-ln(b)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 评估变分下界，公式(13)</span></span><br><span class="line">    E_pD = <span class="number">-0.5</span>*N*safelog(<span class="number">2</span>*<span class="built_in">pi</span>)+<span class="number">0.5</span>*N*E_lntau<span class="number">-0.5</span>*tau*(sumD2<span class="number">-2</span>*mu*sumD+E_mu2);</span><br><span class="line">    E_pmu = <span class="number">-0.5</span>*safelog(<span class="number">2</span>*<span class="built_in">pi</span>)+<span class="number">0.5</span>*E_lntau+<span class="number">0.5</span>*safelog(lambda0)<span class="number">-0.5</span>*lambda0*tau*(E_mu2<span class="number">-2</span>*mu0*mu+mu0^<span class="number">2</span>);</span><br><span class="line">    E_ptau = -safelog(<span class="built_in">gamma</span>(a0))+a0*safelog(b0)+(a0<span class="number">-1</span>)*E_lntau-b0*tau;</span><br><span class="line">    E_qmu = <span class="number">0.5</span>*safelog(<span class="number">2</span>*<span class="built_in">pi</span>)<span class="number">-0.5</span>*safelog(lambda_new)+<span class="number">0.5</span>;</span><br><span class="line">    E_qtau = safelog(<span class="built_in">gamma</span>(a_new))-(a_new<span class="number">-1</span>)*<span class="built_in">psi</span>(a_new)-safelog(b_new)+a_new;</span><br><span class="line">    LB(it) = E_pD + E_pmu + E_ptau + E_qmu + E_qtau;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 可视化求解过程</span></span><br><span class="line">    set(<span class="number">0</span>,<span class="string">'CurrentFigure'</span>,h);</span><br><span class="line">    subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>); plot(mu_real*<span class="built_in">ones</span>(<span class="number">1</span>,it+<span class="number">1</span>), <span class="string">'-r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span>);hold on;plot(mu_est*<span class="built_in">ones</span>(<span class="number">1</span>,it+<span class="number">1</span>), <span class="string">'--r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span> );hold on;plot(mus, <span class="string">'-b.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span>);hold off; title(<span class="string">'Model parameter \mu'</span>); xlabel(<span class="string">'Iteration'</span>); grid on;</span><br><span class="line">    subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>); plot(tau_real*<span class="built_in">ones</span>(<span class="number">1</span>,it+<span class="number">1</span>), <span class="string">'-r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span>);hold on;plot(tau_est*<span class="built_in">ones</span>(<span class="number">1</span>,it+<span class="number">1</span>), <span class="string">'--r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span> );hold on;plot(taus, <span class="string">'-b.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span>);hold off; title(<span class="string">'Model parameter \tau'</span>); xlabel(<span class="string">'Iteration'</span>); grid on;</span><br><span class="line">    subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>); plot(LB, <span class="string">'-r.'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>,<span class="string">'MarkerSize'</span>,<span class="number">10</span>); title(<span class="string">'Lower bound'</span>); xlabel(<span class="string">'Iteration'</span>); grid on;</span><br><span class="line">    subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>); plot(<span class="number">0</span>:<span class="number">0.05</span>:<span class="number">2</span>*tau, gampdf(<span class="number">0</span>:<span class="number">0.05</span>:<span class="number">2</span>*tau, a_new, <span class="number">1.</span>/b_new), <span class="string">'-r.'</span>, <span class="string">'LineWidth'</span>,<span class="number">1.5</span>); title(<span class="string">'Posterior pdf'</span>); xlabel(<span class="string">'Noise precision \tau'</span>); grid on;</span><br><span class="line">    set(findall(h,<span class="string">'type'</span>,<span class="string">'text'</span>),<span class="string">'fontSize'</span>,<span class="number">12</span>);</span><br><span class="line">    drawnow;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">% 判断模型是否收敛</span></span><br><span class="line">    <span class="keyword">if</span> it&gt;<span class="number">3</span></span><br><span class="line">        LB_change = <span class="number">-1</span>*(LB(it) - LB(it<span class="number">-1</span>))/LB(<span class="number">3</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        LB_change = NaN;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> it&gt;<span class="number">10</span> &amp;&amp; (<span class="built_in">abs</span>(LB_change) &lt; tol)</span><br><span class="line">        <span class="built_in">disp</span>(<span class="string">'Converged!'</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">safelog</span><span class="params">(x)</span></span></span><br><span class="line">x(x&lt;<span class="number">1e-300</span>)=<span class="number">1e-200</span>;</span><br><span class="line">x(x&gt;<span class="number">1e300</span>)=<span class="number">1e300</span>;</span><br><span class="line">y=<span class="built_in">log</span>(x);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p><p>求解结果如下图所示，左上与右上两图中的<strong>红色实线</strong>表示生成观测数据模型参数的真值，<strong>红色虚线</strong>表示利用观测数据显式计算得到的模型参数的估计值，<strong>蓝色实线</strong>表示利用变分推断迭代求解的参数估计值。在本例子中，由于推断公式较简单，$\mathbb{E}[\mu]$的计算不依赖于$\mathbb{E}[\tau]$，所以算法在第二次迭代就已经收敛到显式计算的估计值。<br><img src="https://gh-io-1257470807.cos.ap-guangzhou.myqcloud.com/result_converged_3.png" alt="Result Convergence"></p><h2 id="例子-混合高斯模型"><a href="#例子-混合高斯模型" class="headerlink" title="例子-混合高斯模型"></a>例子-混合高斯模型</h2><h3 id="模型推断-1"><a href="#模型推断-1" class="headerlink" title="模型推断"></a>模型推断</h3><h3 id="代码示例-1"><a href="#代码示例-1" class="headerlink" title="代码示例"></a>代码示例</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Christopher M. Bishop. “Pattern recognition and machine learning.” <em>Springer</em>, 2006.</li><li>PRML Errata 1st: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/prml-errata-1st-20110921.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/prml-errata-1st-20110921.pdf</a></li><li>Qibin Zhao, Liqing Zhang, and Andrzej Cichocki. “Bayesian CP factorization of incomplete tensors with automatic rank determination.” <em>IEEE transactions on pattern analysis and machine intelligence</em>, 2015.</li><li><a href="https://github.com/qbzhao/BCPF" target="_blank" rel="noopener">https://github.com/qbzhao/BCPF</a></li><li><a href="https://en.wikipedia.org/wiki/Gamma_distribution" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Gamma_distribution</a></li><li><a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Conjugate_prior</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Bayesian </tag>
            
            <tag> Variational Inference </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
